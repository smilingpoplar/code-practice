WEBVTT
Kind: captions
Language: en

00:00:05.270 --> 00:00:09.075
All right. Let's get started.

00:00:09.075 --> 00:00:14.220
Please try to have a seat if you can find a seat and let's, uh, get the show on the road.

00:00:14.220 --> 00:00:16.730
So welcome everyone to CS221,

00:00:16.730 --> 00:00:18.480
this is Artificial Intelligence.

00:00:18.480 --> 00:00:21.090
Uh, and if you're new to Stanford, welcome to Stanford.

00:00:21.090 --> 00:00:23.220
Um, so first let's do some introductions.

00:00:23.220 --> 00:00:25.875
So I'm Percy, I'm gonna be one of your instructors.

00:00:25.875 --> 00:00:28.215
I'm teaching this class with Dorsa over there.

00:00:28.215 --> 00:00:31.350
So if Dorsa wants to say hi, stand up.

00:00:31.350 --> 00:00:34.950
Hi guys, I'm Dorsa. Um, I'll be co-teaching [NOISE] this class with Percy.

00:00:34.950 --> 00:00:37.280
I'm a professor in robotics and robotic interactions.

00:00:37.280 --> 00:00:41.210
Super excited about teaching this class and [inaudible].

00:00:41.210 --> 00:00:43.385
Great. So we're going to be trading off throughout the quarter.

00:00:43.385 --> 00:00:46.760
And we also have a wonderful teaching team.

00:00:46.760 --> 00:00:48.050
So these are your CAs.

00:00:48.050 --> 00:00:51.500
So if all the CAs could stand up and I'll give you

00:00:51.500 --> 00:00:56.220
each person an opportunity to say three words about what you're interested in.

00:00:56.350 --> 00:01:00.525
So um, let's start with [inaudible] because you're the head CA.

00:01:00.525 --> 00:01:02.340
Hello. My name is [inaudible].

00:01:02.340 --> 00:01:03.420
I'm a PhD student,

00:01:03.420 --> 00:01:06.345
and I'm interested in natural language processing.

00:01:06.345 --> 00:01:07.740
Yay. [LAUGHTER]

00:01:07.740 --> 00:01:11.250
Hi. My name is [inaudible].

00:01:11.250 --> 00:01:12.690
I'm a second year masters student.

00:01:12.690 --> 00:01:13.800
I'm interested in, um,

00:01:13.800 --> 00:01:16.270
machine learning and data mining.

00:01:17.090 --> 00:01:20.625
Hi. I'm [inaudible]. I'm a second year masters student

00:01:20.625 --> 00:01:25.470
and I'm interested in machine learning and natural language processing.

00:01:25.470 --> 00:01:33.840
Hi everyone, my name is [inaudible].

00:01:43.545 --> 00:01:46.060
masters student and I'm interested in

00:02:25.160 --> 00:02:29.250
computer vision.

00:02:29.250 --> 00:02:29.550
[BACKGROUND] [NOISE]

00:02:29.550 --> 00:02:37.230
Let's go over there.

00:02:37.230 --> 00:02:37.530
[BACKGROUND] [NOISE]

00:02:37.530 --> 00:02:40.020
Great. Now, any new TAs in the back?

00:02:40.020 --> 00:02:42.840
No. Well, um, well,

00:02:42.840 --> 00:02:44.625
they're all on the slide.

00:02:44.625 --> 00:02:47.240
Okay. So uh, as you can see,

00:02:47.240 --> 00:02:49.790
we kind of have a very diverse team and so when

00:02:49.790 --> 00:02:52.639
you're thinking about kind of final projects later in the quarter,

00:02:52.639 --> 00:02:55.400
you can tap into this incredible resource.

00:02:55.400 --> 00:02:57.470
Um, so three quick announcements.

00:02:57.470 --> 00:03:01.370
Um, so there's going to be a section every week which will

00:03:01.370 --> 00:03:05.390
cover both kind of review topics and also advanced, uh, uh, topics.

00:03:05.390 --> 00:03:07.660
So this Thursday there's gonna be an overview.

00:03:07.660 --> 00:03:10.790
Um, if you're kinda rusty on Python or rusty on probability,

00:03:10.790 --> 00:03:13.115
come to this and we'll get you up to speed.

00:03:13.115 --> 00:03:15.660
Um, homework, the first homework is out,

00:03:15.660 --> 00:03:16.850
it's posted on the website.

00:03:16.850 --> 00:03:19.280
It's due next Tuesday at 11:00 PM.

00:03:19.280 --> 00:03:21.145
So remember the time, that matters.

00:03:21.145 --> 00:03:23.685
Um, all submissions will be done on Gradescope.

00:03:23.685 --> 00:03:26.880
There's gonna be a Gradescope coast- code that will be posted on, uh, Piazza.

00:03:26.880 --> 00:03:29.850
So look out for that, um, later.

00:03:29.850 --> 00:03:32.595
Okay. So now let's, let's begin.

00:03:32.595 --> 00:03:36.230
So when I first started teaching this class, uh, seven years ago,

00:03:36.230 --> 00:03:39.050
I used to have to motivate why AI was important

00:03:39.050 --> 00:03:42.230
and why if you study it you'll have a lot of impact in the world.

00:03:42.230 --> 00:03:44.210
But I feel like I don't really need to do this.

00:03:44.210 --> 00:03:46.415
Now it's kind of inescapable that you pick up

00:03:46.415 --> 00:03:49.300
the news in the morning and you hear something about, you know, AI.

00:03:49.300 --> 00:03:52.595
And indeed we've seen a lot of success stories, right?

00:03:52.595 --> 00:03:55.460
AIs that can play Jeopardy or play Go,

00:03:55.460 --> 00:03:57.590
Dota 2, pro- even poker,

00:03:57.590 --> 00:04:00.530
all these kind of games at super human level performance.

00:04:00.530 --> 00:04:01.610
It can also, you know,

00:04:01.610 --> 00:04:04.350
read documents and answer questions,

00:04:04.350 --> 00:04:06.240
do speech recognition, uh,

00:04:06.240 --> 00:04:09.280
face recognition, um, even kind of medical imaging.

00:04:09.280 --> 00:04:11.220
And all these tasks are, uh,

00:04:11.220 --> 00:04:13.320
you read about how successful these,

00:04:13.320 --> 00:04:14.985
uh, technologies have been.

00:04:14.985 --> 00:04:18.680
Um, and then if you take a look at outside the kind of the technical circles,

00:04:18.680 --> 00:04:20.120
there's a lot of people, um,

00:04:20.120 --> 00:04:25.490
in policy, um, and trying to ask what is going on with AI.

00:04:25.490 --> 00:04:26.930
And you, you hear about, uh,

00:04:26.930 --> 00:04:28.380
these kind of very, uh,

00:04:28.380 --> 00:04:31.490
broad claims of how transformative AI will be, um,

00:04:31.490 --> 00:04:33.035
to the future of work and,

00:04:33.035 --> 00:04:34.625
um, to society and so on,

00:04:34.625 --> 00:04:36.770
and even some kind of bordering on, uh,

00:04:36.770 --> 00:04:40.235
pretty castro- you know, catastrophic consequences.

00:04:40.235 --> 00:04:43.100
So what's gonna happen in the future,

00:04:43.100 --> 00:04:48.965
no one knows, but it is fair to say that AI will be transformative.

00:04:48.965 --> 00:04:51.470
Um, but how do we get here?

00:04:51.470 --> 00:04:56.285
And to do that, I wanna take a step back to the summer of 1956.

00:04:56.285 --> 00:04:59.170
So the place was Dartmouth College, John McCarthy,

00:04:59.170 --> 00:05:01.620
who was then at MIT, and then,

00:05:01.620 --> 00:05:04.275
uh, after that he founded the Stanford AI Lab, um,

00:05:04.275 --> 00:05:08.485
organized a workshop at Dartmouth College with, um,

00:05:08.485 --> 00:05:10.900
some of the best and brightest minds of the time;

00:05:10.900 --> 00:05:13.590
Marvin Minsky, Claude Shannon, and so on.

00:05:13.590 --> 00:05:19.340
And they had this not so modest goal of trying to think that every aspect of

00:05:19.340 --> 00:05:21.830
learning or any feature of intelligence could be precisely

00:05:21.830 --> 00:05:25.415
captured so that a machine can be just, uh, simulated.

00:05:25.415 --> 00:05:26.870
So they were after the,

00:05:26.870 --> 00:05:30.220
the big question of how do you kind of solve, um, AI.

00:05:30.220 --> 00:05:31.770
So now they didn't make that much,

00:05:31.770 --> 00:05:33.150
uh, progress over the, the summer,

00:05:33.150 --> 00:05:37.280
but a lot of programs and interesting artifacts came about from that time.

00:05:37.280 --> 00:05:40.850
Um, there were programs that could play checkers or prove, uh,

00:05:40.850 --> 00:05:43.655
theorems, and sometimes even better than what,

00:05:43.655 --> 00:05:46.100
um, you know, the human proof will look like.

00:05:46.100 --> 00:05:49.580
Um, and there was a lot of optimism.

00:05:49.580 --> 00:05:51.050
People were really, really excited,

00:05:51.050 --> 00:05:53.915
and you can see these quotes by all these excited people who

00:05:53.915 --> 00:05:57.275
proclaimed that AI would be solved in a matter of years.

00:05:57.275 --> 00:06:02.960
But we know that didn't really happen and there's this kind of folklore example,

00:06:02.960 --> 00:06:05.285
um, people are trying to do machine translation.

00:06:05.285 --> 00:06:09.065
So you take an English sentence like 'The spirit is willing but the flesh is weak',

00:06:09.065 --> 00:06:10.340
you translate into Russian,

00:06:10.340 --> 00:06:11.900
which is what, um,

00:06:11.900 --> 00:06:16.010
the choice language by the US government was at that time, and you could,

00:06:16.010 --> 00:06:17.495
uh, translate back into English;

00:06:17.495 --> 00:06:20.530
and this is what you get, 'The vodka is good but the meat is rotten'.

00:06:20.530 --> 00:06:22.970
Um, so the government didn't think that was too funny,

00:06:22.970 --> 00:06:24.920
so they cut off the funding [LAUGHTER] and,

00:06:24.920 --> 00:06:28.930
um, it became the first AI winter.

00:06:28.930 --> 00:06:32.145
Um, so, so there was a period where, you know,

00:06:32.145 --> 00:06:35.300
AI research was not very active and was not well- very well funded.

00:06:35.300 --> 00:06:37.430
Um, so what went wrong here?

00:06:37.430 --> 00:06:39.540
Um, these were really smart people, right?

00:06:39.540 --> 00:06:42.605
Um, they just got a little maybe ahead of themselves.

00:06:42.605 --> 00:06:47.930
So two problems; one is that the compute was simply not there, right?

00:06:47.930 --> 00:06:50.510
It was millions or even billions of order of

00:06:50.510 --> 00:06:53.670
magnitude compared less than what we have, uh, right now.

00:06:53.670 --> 00:06:54.680
And also, the problems,

00:06:54.680 --> 00:06:55.775
the way they formulate them,

00:06:55.775 --> 00:06:59.120
intrinsically relied on camp- exponential search which, um,

00:06:59.120 --> 00:07:01.250
no matter how much compute you have, you're never going to,

00:07:01.250 --> 00:07:03.060
you know, um, win that race.

00:07:03.060 --> 00:07:06.360
Um, they also have limited, you know, information,

00:07:06.360 --> 00:07:09.140
and this is maybe a kind of a more subtle point that if I gave

00:07:09.140 --> 00:07:12.275
you infinite compute and I asked you to translate,

00:07:12.275 --> 00:07:15.800
I don't think you would be able to figure it out because it's not a computation problem.

00:07:15.800 --> 00:07:18.215
You just need to learn the language and you need to

00:07:18.215 --> 00:07:21.335
experience all the subtleties of language to be able to,

00:07:21.335 --> 00:07:23.360
you know, translate [NOISE].

00:07:23.360 --> 00:07:25.470
But on the other hand, AI wasn't solved,

00:07:25.470 --> 00:07:27.600
but a lot of interesting,

00:07:27.600 --> 00:07:30.590
um, contributions to computer science came out of it.

00:07:30.590 --> 00:07:31.880
Lisp was- is- uh,

00:07:31.880 --> 00:07:33.635
had a lot of ideas that

00:07:33.635 --> 00:07:36.680
underlay ma- many of the high level programming languages we have,

00:07:36.680 --> 00:07:39.650
garbage collection, um, time-sharing, allowing, uh,

00:07:39.650 --> 00:07:42.560
multiple people to use the same- one computer at the same time,

00:07:42.560 --> 00:07:43.820
which is something that,

00:07:43.820 --> 00:07:45.470
uh, we kind of take for granted.

00:07:45.470 --> 00:07:49.365
And also this paradigm of separating what you want to compute,

00:07:49.365 --> 00:07:51.705
which is modeling, and how you do it,

00:07:51.705 --> 00:07:54.805
which is inference, which we'll get to a little bit later.

00:07:54.805 --> 00:07:59.295
Okay. So um, people forget quickly and, um,

00:07:59.295 --> 00:08:00.620
in the '70s and '80s,

00:08:00.620 --> 00:08:04.805
there was a renewed generation of people getting excited about AI again.

00:08:04.805 --> 00:08:07.790
Um, and this time it was all about knowledge, right?

00:08:07.790 --> 00:08:10.205
Knowledge is power and,

00:08:10.205 --> 00:08:13.690
um, there were a lot of expert systems which were created.

00:08:13.690 --> 00:08:17.435
And the idea is that if you could encode expert's knowledge about the world,

00:08:17.435 --> 00:08:19.010
then you could do kind of amazing things,

00:08:19.010 --> 00:08:22.820
and at the time the knowledge was encoded in generally a set of rules.

00:08:22.820 --> 00:08:26.420
Um, and there were a lot of programs that was written,

00:08:26.420 --> 00:08:29.015
and you'll notice that the, the scope is much narrower now.

00:08:29.015 --> 00:08:30.740
The goal isn't to solve it- all of AI,

00:08:30.740 --> 00:08:34.520
but to really focus on some choice and problems like

00:08:34.520 --> 00:08:38.660
diagnosing the diseases or converting customer's order parts into parts,

00:08:38.660 --> 00:08:42.035
and, uh- customer orders into parts and, uh,

00:08:42.035 --> 00:08:44.000
this was the first time that AI, I think,

00:08:44.000 --> 00:08:46.640
really had a real impact on industries.

00:08:46.640 --> 00:08:49.310
So uh, people were actually able to make useful,

00:08:49.310 --> 00:08:51.050
you know, products out of this.

00:08:51.050 --> 00:08:54.230
And knowledge did actually play a key ingredient in curbing this,

00:08:54.230 --> 00:08:57.340
you know, exponential growth that people were worried about.

00:08:57.340 --> 00:08:59.520
But of course, um,

00:08:59.520 --> 00:09:00.840
it didn't last long.

00:09:00.840 --> 00:09:03.980
Um, knowledge as deterministic rules was simply

00:09:03.980 --> 00:09:07.730
not rich enough to capture all the kind of nuances of the world.

00:09:07.730 --> 00:09:12.500
It required a lot of manual effort to maintain and, um, again, um,

00:09:12.500 --> 00:09:17.345
a pattern of over-promising and under-delivering that seems to plague, um,

00:09:17.345 --> 00:09:23.930
AI people, led to the collapse of the field and the kind of a second AI winter.

00:09:23.930 --> 00:09:28.815
Um, okay, so that's not the end of the story either.

00:09:28.815 --> 00:09:31.780
But actually it's not kind of really the beginning either.

00:09:31.780 --> 00:09:36.235
Um, so I'm going to step back further in time to 1943.

00:09:36.235 --> 00:09:38.655
So what happened in 1943?

00:09:38.655 --> 00:09:40.500
So there was, um,

00:09:40.500 --> 00:09:43.740
a neuroscientist, McCulloch; and logician, Pitts,

00:09:43.740 --> 00:09:46.270
who were wondering and marveling at how

00:09:46.270 --> 00:09:50.560
the human brain is able to do all of these kind of complicated things.

00:09:50.560 --> 00:09:54.100
And they wanted to kind of formulate a theory about how this could all happen.

00:09:54.100 --> 00:09:55.960
So they developed a theory of,

00:09:55.960 --> 00:09:58.480
um, artificial neural networks, um,

00:09:58.480 --> 00:10:01.205
and this is kind of you can think about the root as of,

00:10:01.205 --> 00:10:03.045
you know, deep learning in some sense.

00:10:03.045 --> 00:10:07.240
Um, and what's interesting is that they looked at, um,

00:10:07.240 --> 00:10:09.350
neurons and logic, which are

00:10:09.350 --> 00:10:12.230
two things that you might not kind of necessarily associate with each other,

00:10:12.230 --> 00:10:15.145
and showed how they were kind of connected mathematically.

00:10:15.145 --> 00:10:19.615
And a lot of that early work in this era were of- around artificial neural networks,

00:10:19.615 --> 00:10:23.600
was about studying them kinda from a mathematical perspective.

00:10:23.600 --> 00:10:26.080
Um, because at that time, the compute wasn't there,

00:10:26.080 --> 00:10:30.450
you couldn't really run any kind of training new models or um.

00:10:30.450 --> 00:10:33.580
And then 1969, something interesting happened.

00:10:33.580 --> 00:10:36.985
So there's this book by Minsky and Papert called Perceptrons.

00:10:36.985 --> 00:10:39.730
And this book did a lot of mathematical analysis.

00:10:39.730 --> 00:10:44.530
And it also showed that linear models, one of the results of many,

00:10:44.530 --> 00:10:48.610
was showing that linear classifiers couldn't solve the XOR problem.

00:10:48.610 --> 00:10:53.380
Um, the problem is- another way to think about the problem is basically given two inputs,

00:10:53.380 --> 00:10:57.010
can you tell whether they are the same or not, or different.

00:10:57.010 --> 00:10:59.740
And, um, so it's kind of not a-

00:10:59.740 --> 00:11:02.935
shouldn't be a hard problem but linear classifiers can do it.

00:11:02.935 --> 00:11:04.750
And for some reason,

00:11:04.750 --> 00:11:05.890
which I don't quite understand,

00:11:05.890 --> 00:11:08.620
it killed off neural nets research even though they

00:11:08.620 --> 00:11:11.350
had said nothing about if you had a deeper network, what it could do.

00:11:11.350 --> 00:11:14.590
Um, but it's often cited that this book, ah,

00:11:14.590 --> 00:11:17.470
swung things from people who were interested in

00:11:17.470 --> 00:11:22.255
neural networks to the field of AI being very symbolic and logic driven.

00:11:22.255 --> 00:11:26.005
Um, but there was always this kinda minority group, um,

00:11:26.005 --> 00:11:28.990
who were really invested in and believed in, um,

00:11:28.990 --> 00:11:30.430
the power of neural networks,

00:11:30.430 --> 00:11:33.310
and I think this was always just kind of a matter of time.

00:11:33.310 --> 00:11:36.715
So in the '80s, there was a renewed interest.

00:11:36.715 --> 00:11:39.040
Um, people kind of discovered or

00:11:39.040 --> 00:11:42.745
rediscovered the backpropagation algorithm which allowed a kind of,

00:11:42.745 --> 00:11:46.270
for a generic algorithm that could train these multilayer neural networks

00:11:46.270 --> 00:11:50.335
because single layer remember was insufficient to do a lot of things.

00:11:50.335 --> 00:11:53.200
And then one of the kind of the early success stories,

00:11:53.200 --> 00:11:55.555
as Yann LeCun in 1989,

00:11:55.555 --> 00:11:58.270
applied a convolutional neural network and

00:11:58.270 --> 00:12:01.030
was able to recognize hand digit- written digits,

00:12:01.030 --> 00:12:03.580
and this actually got deployed, um,

00:12:03.580 --> 00:12:06.400
by the USPS and was reading kind of zip codes.

00:12:06.400 --> 00:12:09.220
Um, so this was, you know, great, ah,

00:12:09.220 --> 00:12:11.860
but it wasn't until this decade that the,

00:12:11.860 --> 00:12:15.295
um, this area of neural networks really kind of took off,

00:12:15.295 --> 00:12:17.395
um, under the moniker deep learning.

00:12:17.395 --> 00:12:18.895
Um, and, you know,

00:12:18.895 --> 00:12:24.385
AlexNet in 2012 was kind of a huge transformation, um,

00:12:24.385 --> 00:12:25.630
where they show gains on the,

00:12:25.630 --> 00:12:30.670
kind of ImageNet ba- benchmark and overnight transformed the computer vision community.

00:12:30.670 --> 00:12:33.295
Um, AlphaGo as, you know, many of you know,

00:12:33.295 --> 00:12:34.735
and many kind of other,

00:12:34.735 --> 00:12:37.460
um, and there were kind of the rest is history.

00:12:37.500 --> 00:12:42.820
Okay, so- so there's this kind of two intellectual traditions.

00:12:42.820 --> 00:12:45.370
Um, you know, the name AI has always been

00:12:45.370 --> 00:12:48.520
associated with the kind of John McCarthy logical tradition,

00:12:48.520 --> 00:12:49.810
that's kind of where it started.

00:12:49.810 --> 00:12:52.620
But, um, as you can see that there is also

00:12:52.620 --> 00:12:55.575
kind of this neuroscience inspired tradition of AI,

00:12:55.575 --> 00:12:57.540
and the two are kind of really had

00:12:57.540 --> 00:12:59.580
some deep philosophical differences and over

00:12:59.580 --> 00:13:02.660
the decades fought with each other kind of quite a bit.

00:13:02.660 --> 00:13:05.620
But I want to pause for a moment and really think about,

00:13:05.620 --> 00:13:08.485
[NOISE] maybe if there were actually kind of deeper connections here.

00:13:08.485 --> 00:13:09.970
Remember McCulloch and Pitts,

00:13:09.970 --> 00:13:12.235
they were studying artificial and neural networks,

00:13:12.235 --> 00:13:15.160
but the connection was to logic, right?

00:13:15.160 --> 00:13:17.065
So from even in the very beginning,

00:13:17.065 --> 00:13:19.210
there is kind of this synergy that, you know,

00:13:19.210 --> 00:13:22.060
some- some people can kind of often overlook.

00:13:22.060 --> 00:13:24.055
And if you take a look at AlphaGo,

00:13:24.055 --> 00:13:26.770
which [NOISE] if you think about the game of Go or many games,

00:13:26.770 --> 00:13:33.370
it's a mathematically, you can write down the rules of Go in logic in just a few lines.

00:13:33.370 --> 00:13:37.105
So it's a mathematically well-defined logical- logic puzzle in some sense.

00:13:37.105 --> 00:13:40.840
But somehow, the- the power of neural networks

00:13:40.840 --> 00:13:45.730
allows you to develop these models that actually play Go really- really well.

00:13:45.730 --> 00:13:49.570
So this is kinda one of the deep mysteries that has, kind of,

00:13:49.570 --> 00:13:53.590
uh, I think is kind of o- opens standard challenge, you know, in AI.

00:13:53.590 --> 00:13:59.110
Um, as with any story it's not a full picture,

00:13:59.110 --> 00:14:02.200
and I want to point out on this slide that,

00:14:02.200 --> 00:14:05.650
AI has drawn from a lot of different, you know,

00:14:05.650 --> 00:14:08.050
fields, many of the techniques that we're gonna look at,

00:14:08.050 --> 00:14:09.685
for example, maximum likelihood,

00:14:09.685 --> 00:14:14.650
came from your statistics or games came from economics, optimizations,

00:14:14.650 --> 00:14:17.350
gradient descent, hence from- was, you know,

00:14:17.350 --> 00:14:20.410
in the '50s completely unrelated to AI.

00:14:20.410 --> 00:14:23.215
But these techniques kind of developed in a different context.

00:14:23.215 --> 00:14:25.690
And so AI is kind of like,

00:14:25.690 --> 00:14:27.400
you know, it's kind of like a New York City.

00:14:27.400 --> 00:14:31.480
It's- it's like a melting pot where a lot of the- these

00:14:31.480 --> 00:14:35.725
techniques that kind of unified and apply to kind of interesting problems.

00:14:35.725 --> 00:14:37.900
And that's what makes it, I think really interesting

00:14:37.900 --> 00:14:40.300
because of the- the new [NOISE] avenues

00:14:40.300 --> 00:14:45.950
that are opened up by kind of unique combinations of, um, existing techniques.

00:14:47.010 --> 00:14:51.625
Okay, so- so that was a really bre- brief history of,

00:14:51.625 --> 00:14:53.380
you know, where- how we got here.

00:14:53.380 --> 00:14:56.515
Um, now I want to pause for a moment and think about,

00:14:56.515 --> 00:14:58.435
you know, what is- what is the goal?

00:14:58.435 --> 00:15:00.865
What- what AI people are trying to do?

00:15:00.865 --> 00:15:03.970
And again this- this is kind of there's two ways to think about

00:15:03.970 --> 00:15:09.580
this which and- sometimes the conflation of these causes a lot of confusion.

00:15:09.580 --> 00:15:14.050
Um, so I like to think about it as AI as agents,

00:15:14.050 --> 00:15:15.205
and AI as tools.

00:15:15.205 --> 00:15:19.405
So the first view asks the kind of standard question of,

00:15:19.405 --> 00:15:23.815
how can we create or recreate intelligence?

00:15:23.815 --> 00:15:25.300
And the second one asked, you know,

00:15:25.300 --> 00:15:28.540
how can we use technology to kind of benefit, you know, society?

00:15:28.540 --> 00:15:31.915
[NOISE] And these two are obviously very related and they have, ah,

00:15:31.915 --> 00:15:34.825
a lot of shared technical,

00:15:34.825 --> 00:15:36.910
um, overlap, but, you know,

00:15:36.910 --> 00:15:39.175
philosophically they're kind of different.

00:15:39.175 --> 00:15:41.350
So let me kind of explain this a little bit.

00:15:41.350 --> 00:15:43.915
So the idea with AI agents is,

00:15:43.915 --> 00:15:46.195
and this is, I think a lot of what,

00:15:46.195 --> 00:15:49.000
um, um, gets associated with AI,

00:15:49.000 --> 00:15:51.220
um, and especially as, you know, with science fiction.

00:15:51.220 --> 00:15:54.790
That kind of, ah, po- portrayal certainly kind of

00:15:54.790 --> 00:15:59.950
encourages this kinda view where [NOISE] you're human- we're human beings.

00:15:59.950 --> 00:16:02.530
And what you do is you look in the mirror and you say,

00:16:02.530 --> 00:16:05.740
wow, that's must- that's a really smart person.

00:16:05.740 --> 00:16:10.075
And you think okay, how- how- what- what- what can humans do that is,

00:16:10.075 --> 00:16:11.590
you know, so amazing.

00:16:11.590 --> 00:16:13.225
Well, they can, um,

00:16:13.225 --> 00:16:16.540
they can see and they can perceive the world, recognize objects.

00:16:16.540 --> 00:16:20.470
Um, they can grasp cups and drink water and not spill it.

00:16:20.470 --> 00:16:26.320
[NOISE] Um, they can communicate using language as I'm doing to you right now.

00:16:26.320 --> 00:16:28.960
Um, we know facts about the world,

00:16:28.960 --> 00:16:30.880
[NOISE] declarative knowledge such as what's the capital of

00:16:30.880 --> 00:16:33.760
France and procedural knowledge like how to ride a bike.

00:16:33.760 --> 00:16:38.245
We can reason with this knowledge and maybe ride a bike to the capital of France.

00:16:38.245 --> 00:16:40.705
And then, really importantly,

00:16:40.705 --> 00:16:42.940
we're not born with all of this, right?

00:16:42.940 --> 00:16:44.799
We're born with basically nothing,

00:16:44.799 --> 00:16:46.060
none of these capabilities,

00:16:46.060 --> 00:16:48.430
but we are born with the capacity and

00:16:48.430 --> 00:16:52.420
potential to acquire these over time through experience.

00:16:52.420 --> 00:16:55.180
And learning it seems to be kind of this critical ingredient,

00:16:55.180 --> 00:16:59.185
which drives a lot of the success in AI today but also with,

00:16:59.185 --> 00:17:01.780
um, you, know, human intelligence it's clear that learning plays

00:17:01.780 --> 00:17:06.580
such a central role in getting us to the level that we're operating at.

00:17:06.580 --> 00:17:10.345
So each of these areas has kind of spawned entire sub-fields,

00:17:10.345 --> 00:17:13.870
and people in it are kind of wondering about how you

00:17:13.870 --> 00:17:17.740
can make artificial systems that have the language,

00:17:17.740 --> 00:17:24.430
or the motor, or the visual perceptual capabilities that, you know, humans have.

00:17:24.430 --> 00:17:26.860
But are we there yet?

00:17:26.860 --> 00:17:31.825
Um, and I would- I would like to think that we are, ah, very far.

00:17:31.825 --> 00:17:35.740
So if you look at the way that machines are, have been successful,

00:17:35.740 --> 00:17:39.190
it's all with a narrow set of tasks and, you know,

00:17:39.190 --> 00:17:41.155
millions or billions of examples,

00:17:41.155 --> 00:17:43.705
and you just crunch a lot of computation,

00:17:43.705 --> 00:17:46.915
and you can really kind of optimize,

00:17:46.915 --> 00:17:50.815
um, every- any tasks that you're going to come-come up with.

00:17:50.815 --> 00:17:53.950
Whereas humans operate in a very different regime.

00:17:53.950 --> 00:17:56.710
[NOISE] They don't necessarily do any, you know,

00:17:56.710 --> 00:17:59.830
one thing well, but they are have such a kind of

00:17:59.830 --> 00:18:01.420
diverse set of, you know,

00:18:01.420 --> 00:18:04.390
experiences, can solve a diverse set of tasks and

00:18:04.390 --> 00:18:08.020
learn from each individual tasks from very few examples.

00:18:08.020 --> 00:18:10.345
And still it's a kind of a grand challenge,

00:18:10.345 --> 00:18:12.970
in from a, uh, cognitive perspective,

00:18:12.970 --> 00:18:20.240
how you can build systems with this level of capability in that humans have.

00:18:20.520 --> 00:18:24.010
So the other view is, you know, AI tools.

00:18:24.010 --> 00:18:26.290
Basically we say okay well, you know,

00:18:26.290 --> 00:18:28.285
it's kind of cool to think about how we can,

00:18:28.285 --> 00:18:30.820
uh, you know, recreate intelligence.

00:18:30.820 --> 00:18:34.794
But, you know, we don't really care about making more,

00:18:34.794 --> 00:18:36.580
um, things like humans.

00:18:36.580 --> 00:18:37.900
We already have a way of, you know,

00:18:37.900 --> 00:18:40.030
doing that, that's called babies.

00:18:40.030 --> 00:18:40.660
[LAUGHTER].

00:18:40.660 --> 00:18:43.990
Um, so when instead what we'd really like to do is not

00:18:43.990 --> 00:18:47.485
making something that's like a human but making systems that help humans.

00:18:47.485 --> 00:18:48.730
Because, you know, after all,

00:18:48.730 --> 00:18:51.310
we're- we're humans, I guess it's a little bit selfish but,

00:18:51.310 --> 00:18:53.140
um, we're in charge right now.

00:18:53.140 --> 00:18:57.580
Um, and- and a lot of this- this view and a lot of

00:18:57.580 --> 00:19:01.810
the success stories in AI are really different from the things that you expect,

00:19:01.810 --> 00:19:05.635
you know, this, uh, this humanoid robot to come into your house and be able to do.

00:19:05.635 --> 00:19:08.830
For example this is a project from Stefano Ermon's group.

00:19:08.830 --> 00:19:11.650
Um, there's a lot of poverty in the world and, um,

00:19:11.650 --> 00:19:13.930
part of it is- is just kind of understanding

00:19:13.930 --> 00:19:17.365
what's- what's going on and they had this idea of using,

00:19:17.365 --> 00:19:20.725
uh, computer vision on satellite imagery to predict things like,

00:19:20.725 --> 00:19:23.215
you know p-, uh, GDP.

00:19:23.215 --> 00:19:26.350
Um, so this is obviously not a task that, you know,

00:19:26.350 --> 00:19:28.510
the- our ancestors in Africa were like,

00:19:28.510 --> 00:19:30.235
you know, getting really good at.

00:19:30.235 --> 00:19:31.840
Um, but nonetheless it uses

00:19:31.840 --> 00:19:35.200
convolutional neural networks which is a technique that was inspired by,

00:19:35.200 --> 00:19:39.505
um, you know the brain and so that's- that's kind of interesting.

00:19:39.505 --> 00:19:43.360
Um, you can also have another application for saving

00:19:43.360 --> 00:19:47.365
energy by trying to figure out when to cool on datacenters.

00:19:47.365 --> 00:19:49.120
Um, as AI, is, uh,

00:19:49.120 --> 00:19:52.150
being deployed in more kind of mission critical s-, uh,

00:19:52.150 --> 00:19:55.945
situations such as self-driving cars or authentication.

00:19:55.945 --> 00:19:59.635
There are- there are a f- few th- new issues that come up.

00:19:59.635 --> 00:20:04.690
So for example, there are- thi- this phenomenon called adversarial examples,

00:20:04.690 --> 00:20:06.730
um, where you can take,

00:20:06.730 --> 00:20:09.939
um, these cool-looking glasses,

00:20:09.939 --> 00:20:11.470
you can put them on your face,

00:20:11.470 --> 00:20:15.070
and you can fool the computer, um,

00:20:15.070 --> 00:20:16.600
as- of- save our-

00:20:16.600 --> 00:20:21.040
our face recognition system to think that you're actually, you know, someone else.

00:20:21.040 --> 00:20:23.245
Um, or you can post these, uh,

00:20:23.245 --> 00:20:26.215
s- stickers on stop signs and you'd get this,

00:20:26.215 --> 00:20:28.930
uh- s- save our system to think that it's a,

00:20:28.930 --> 00:20:30.610
um, a speed limit sign.

00:20:30.610 --> 00:20:34.510
So there's obviously- there's- clearly these are, you know,

00:20:34.510 --> 00:20:38.110
big problems if we think about that the widespread deploy- deployment of AI.

00:20:38.110 --> 00:20:43.675
Um, there's also a less catastrophically but also p- pretty, um,

00:20:43.675 --> 00:20:46.150
you know, upsetting which is, uh,

00:20:46.150 --> 00:20:50.515
biases that you- many of you probably have read in the news about.

00:20:50.515 --> 00:20:55.180
So for example, if you take Malay which is a language that, uh, doesn't distinguish,

00:20:55.180 --> 00:21:00.415
um, in this writing form between he and she and you stick it into Google Translate.

00:21:00.415 --> 00:21:02.620
Um, you see that she works as a nurse but he

00:21:02.620 --> 00:21:05.095
works as a programmer, which is encoding certain,

00:21:05.095 --> 00:21:07.045
uh, societal biases, um,

00:21:07.045 --> 00:21:08.785
in the actual models.

00:21:08.785 --> 00:21:12.685
And one kind of an important point I wanna bring up is that,

00:21:12.685 --> 00:21:17.065
you know, it's -- it's how is machine learning and AI kinda working today?

00:21:17.065 --> 00:21:20.950
Well, it's, um, you know, society exists.

00:21:20.950 --> 00:21:23.140
Society is generating a lot of data.

00:21:23.140 --> 00:21:24.475
We're training on this data,

00:21:24.475 --> 00:21:26.770
and kind of trying to fit the data and try and mimic

00:21:26.770 --> 00:21:29.245
what it's doing and then using predictions on it.

00:21:29.245 --> 00:21:31.540
What could possibly go wrong, right?

00:21:31.540 --> 00:21:35.440
Um, and so- so certainly people- a lot of people have been thinking about, um,

00:21:35.440 --> 00:21:40.765
how these biases are kind of creeping up and is an open and active area of research.

00:21:40.765 --> 00:21:42.520
Something a little bit more, uh,

00:21:42.520 --> 00:21:45.505
kind of s- sensitive is, you know,

00:21:45.505 --> 00:21:49.375
asking well,  these systems are being deployed to

00:21:49.375 --> 00:21:54.100
all these- all these people whether they kinda want it or- or want it or not.

00:21:54.100 --> 00:21:56.845
Um, and this, uh, this actually touches on,

00:21:56.845 --> 00:21:59.215
you know, people's, uh, you know, livelihoods.

00:21:59.215 --> 00:22:01.810
It actually impacts people's lives in a serious way.

00:22:01.810 --> 00:22:05.140
Um, so Northpointe was this company that developed a- a software called

00:22:05.140 --> 00:22:08.605
COMPAS that tries to predict how risky,

00:22:08.605 --> 00:22:13.600
um, criminal risk or how someone- how risky someone is essentially.

00:22:13.600 --> 00:22:18.400
Um, and ProPublica this organization realized whoa, whoa, whoa, whoa.

00:22:18.400 --> 00:22:20.125
You have this system that, uh,

00:22:20.125 --> 00:22:23.305
given an individual didn't reoffend is actually, um,

00:22:23.305 --> 00:22:28.540
more- twice as likely to classify blacks as incorrectly as, you know, non-blacks.

00:22:28.540 --> 00:22:31.465
So this is, uh, seems pretty problematic.

00:22:31.465 --> 00:22:34.015
And then Northpointe comes back and says actually,

00:22:34.015 --> 00:22:36.340
you know, I think we- I think we're being fair.

00:22:36.340 --> 00:22:39.235
Um, so given a risk score of 7, uh,

00:22:39.235 --> 00:22:44.035
we were fair because 60% of whites reoffended and 60% of blacks reoffended.

00:22:44.035 --> 00:22:51.460
Um, the- the point here is that there's- there's- there's actually no,

00:22:51.460 --> 00:22:54.670
um, solution to this in some sense sadly.

00:22:54.670 --> 00:22:57.340
Um, so people are finding or formulating different notions

00:22:57.340 --> 00:22:59.500
of fairness and equality between,

00:22:59.500 --> 00:23:03.925
um, how you predict or record it on different kind of, um, groups.

00:23:03.925 --> 00:23:08.320
But, um, or you can have different notions of fairness

00:23:08.320 --> 00:23:13.615
and which all seem reasonable from first principles but mathematically they can be,

00:23:13.615 --> 00:23:15.730
um, incompatible with each other.

00:23:15.730 --> 00:23:18.460
So this is- this is again an open area of

00:23:18.460 --> 00:23:21.730
research where we're trying to figure out as a society how,

00:23:21.730 --> 00:23:24.100
um, to deal with the schema that

00:23:24.100 --> 00:23:28.600
machine learning might be using these in kind of critical situations.

00:23:28.600 --> 00:23:31.330
Okay. So summary so far,

00:23:31.330 --> 00:23:34.135
um, there's an agent's view.

00:23:34.135 --> 00:23:39.820
Um, we're trying to really kind of dream and think about how do you get

00:23:39.820 --> 00:23:45.640
these capabilities like learning from very few examples that humans have into,

00:23:45.640 --> 00:23:48.145
you know, machines and a whole- maybe opening up a kind of

00:23:48.145 --> 00:23:51.250
a- a different set of technical capabilities.

00:23:51.250 --> 00:23:52.960
But at the same time,

00:23:52.960 --> 00:23:55.210
and we really need to be thinking about how

00:23:55.210 --> 00:23:59.050
these AI systems are affecting the real world.

00:23:59.050 --> 00:24:00.850
And things like security,

00:24:00.850 --> 00:24:04.480
and biases, and fairness all kind of show up.

00:24:04.480 --> 00:24:07.000
It's also interesting to note that, you know,

00:24:07.000 --> 00:24:09.520
a lot of the challenges in deployment of an

00:24:09.520 --> 00:24:13.330
AI system don't really have necessarily to do with,

00:24:13.330 --> 00:24:14.785
um, you know, humans at all.

00:24:14.785 --> 00:24:18.040
I mean, humans are incredibly biased but that doesn't mean we want

00:24:18.040 --> 00:24:21.610
to build systems kind of in our- in,

00:24:21.610 --> 00:24:28.220
um, that mimic humans and kind of inherit all the kind of the flaws that humans have.

00:24:28.830 --> 00:24:33.490
Okay. Any questions about this?

00:24:33.490 --> 00:24:35.810
Maybe I'll pause for a moment.

00:24:48.600 --> 00:24:51.220
So let's go on.

00:24:51.220 --> 00:24:53.785
Um, so what I wanna do next

00:24:53.785 --> 00:24:58.030
is give an overview of the different topics, um, in the course.

00:24:58.030 --> 00:25:04.330
Um, and the way to think about all this is that,

00:25:04.330 --> 00:25:07.660
um, in AI we're trying to solve really complex problems.

00:25:07.660 --> 00:25:10.090
The real world is really complicated.

00:25:10.090 --> 00:25:13.510
And- but at the end of the day we want to produce

00:25:13.510 --> 00:25:18.490
some software or maybe some hardware that actually runs and does stuff, right?

00:25:18.490 --> 00:25:21.760
And so there's a very considerable gap between these things.

00:25:21.760 --> 00:25:26.440
And so how do you even approach something like self-driving cars or,

00:25:26.440 --> 00:25:29.005
um, you know, d- diagnosing diseases?

00:25:29.005 --> 00:25:34.210
You probably shouldn't just like go sit down at a terminal and start typing because then,

00:25:34.210 --> 00:25:37.420
um, there- there's no kind of- no overarching structure.

00:25:37.420 --> 00:25:42.280
So what this class is going to do is to give you one example of

00:25:42.280 --> 00:25:47.050
a structure which will hopefully help you approach hard problems,

00:25:47.050 --> 00:25:50.680
and think about how to solve them in a kind of more principled way.

00:25:50.680 --> 00:25:53.620
Um, so this is a paradigm that I call the,

00:25:53.620 --> 00:25:56.650
um, modeling inference and learning paradigm.

00:25:56.650 --> 00:26:06.170
Um, so the idea here is that there's three pillars which I'll explain in a bit.

00:26:08.850 --> 00:26:14.095
And, uh, we can focus on each one of these things kind of in turn.

00:26:14.095 --> 00:26:18.160
So the first pillar is modeling. So what is modeling?

00:26:18.160 --> 00:26:20.200
The modeling is taking the real world,

00:26:20.200 --> 00:26:24.610
which is really complicated and building a model out of it. So what is a model?

00:26:24.610 --> 00:26:29.755
Model is a simplification that is mathematically precise so that you can,

00:26:29.755 --> 00:26:31.270
you know, do something with it,

00:26:31.270 --> 00:26:32.800
uh, on a computer.

00:26:32.800 --> 00:26:36.730
Um, one of the things that's necessary is that modeling, um,

00:26:36.730 --> 00:26:39.310
necessarily has to simplify things and,

00:26:39.310 --> 00:26:41.170
you know, throw away information.

00:26:41.170 --> 00:26:42.580
Um, so one of the kind of,

00:26:42.580 --> 00:26:43.885
uh, the, you know,

00:26:43.885 --> 00:26:45.910
the art is to figure out

00:26:45.910 --> 00:26:48.985
what information to pay attention to and what information to keep.

00:26:48.985 --> 00:26:51.430
Um, so this is going to be important for example when you

00:26:51.430 --> 00:26:53.905
work on your final projects and you have a real world problem,

00:26:53.905 --> 00:26:55.720
you need to figure out, um,

00:26:55.720 --> 00:26:59.035
you can't have everything and you have to figure out judiciously how to,

00:26:59.035 --> 00:27:01.225
um, manage your- your resources.

00:27:01.225 --> 00:27:07.185
So here's an example. If you want to for example build a- a system that can find, uh,

00:27:07.185 --> 00:27:11.550
the best way to get from point A to point B in a graph- in a- in a city you can

00:27:11.550 --> 00:27:16.800
formulate the model as a- a graph where nodes are points in the city,

00:27:16.800 --> 00:27:22.180
and edges rep- represent ab- ability to go between these points with some sort of cost,

00:27:22.180 --> 00:27:24.580
um, on the edges.

00:27:24.580 --> 00:27:31.165
Okay. So now once you have your model you can do, uh, inference.

00:27:31.165 --> 00:27:35.740
And what inference means is asking questions about your model.

00:27:35.740 --> 00:27:40.450
So here's a model you can ask for example how- what is the shortest path from,

00:27:40.450 --> 00:27:43.825
um, this point, uh, to this point.

00:27:43.825 --> 00:27:49.095
Right. And that's because now your model land is a mathematically well-defined, uh,

00:27:49.095 --> 00:27:52.470
problem now you can- it's within the realm of,

00:27:52.470 --> 00:27:55.155
uh, you know, deve- developing algorithms to,

00:27:55.155 --> 00:27:56.825
you know, solve that problem.

00:27:56.825 --> 00:27:59.530
And most of the inference is ki- being able to

00:27:59.530 --> 00:28:03.655
do these computations, um, really efficiently.

00:28:03.655 --> 00:28:08.080
And finally learning addresses the problem,

00:28:08.080 --> 00:28:09.790
where does this model come from?

00:28:09.790 --> 00:28:13.000
So in any kind of realistic setting,

00:28:13.000 --> 00:28:16.075
um, the model might have a lot of parameters.

00:28:16.075 --> 00:28:19.045
Maybe it has, you know, millions of parameters and how do you

00:28:19.045 --> 00:28:22.330
s- if it- if it- wants to be faithful to the,

00:28:22.330 --> 00:28:26.245
you know, real world that how do you get all this, uh, information there.

00:28:26.245 --> 00:28:30.895
Um, manually p- encoding this information turns out not to be a good idea.

00:28:30.895 --> 00:28:33.145
This is, um, in some sense what,

00:28:33.145 --> 00:28:36.340
um, AI from the '80s was trying to do.

00:28:36.340 --> 00:28:40.555
Um, so the learning paradigm is as follows.

00:28:40.555 --> 00:28:44.065
What we're gonna do is specify a model without parameters.

00:28:44.065 --> 00:28:45.745
Think about it as a skeleton.

00:28:45.745 --> 00:28:50.260
So in this case we have a graph but we don't know what the edge weights are.

00:28:50.260 --> 00:28:54.100
Um, and now we have some data.

00:28:54.100 --> 00:28:57.100
So maybe we have data of the form people tried

00:28:57.100 --> 00:29:00.040
to go from X to Y and they took 10 minutes,

00:29:00.040 --> 00:29:02.260
or an hour, or so on, um,

00:29:02.260 --> 00:29:06.310
and then from this data we can learn to fit the parameters of the model.

00:29:06.310 --> 00:29:07.990
We can assign, um,

00:29:07.990 --> 00:29:13.750
costs to the edges that kind of are representative of what the data is telling us, okay?

00:29:13.750 --> 00:29:14.980
So now in this way,

00:29:14.980 --> 00:29:17.635
we can write down a model without parameters,

00:29:17.635 --> 00:29:22.075
feed the data, apply a generic learning algorithm and get a model with parameters.

00:29:22.075 --> 00:29:23.875
And now we can go back and do, um,

00:29:23.875 --> 00:29:27.310
inference and ask questions, you know, about this.

00:29:27.310 --> 00:29:30.685
Okay. So this is kind of the- the- the paradigm.

00:29:30.685 --> 00:29:33.340
And I want to really emphasize that, you know,

00:29:33.340 --> 00:29:37.540
learning is not- as I've presented is really not about

00:29:37.540 --> 00:29:42.190
any one particular algorithm like nearest neighbors or neural networks.

00:29:42.190 --> 00:29:46.600
It's really a kind of a philosophy of how you go about approaching problems by

00:29:46.600 --> 00:29:48.940
defining a model and then not

00:29:48.940 --> 00:29:52.610
having to specify all the details but filling them in later.

00:29:53.400 --> 00:29:58.705
Okay. So here is the plan for the course.

00:29:58.705 --> 00:30:02.935
We're gonna go from low-level intelligence to high-level intelligence;

00:30:02.935 --> 00:30:05.170
and this is the intelligence of,

00:30:05.170 --> 00:30:08.530
um, of the, of the models that we're gonna be talking about.

00:30:08.530 --> 00:30:11.680
So first we're gonna talk about machine learning,

00:30:11.680 --> 00:30:13.825
and like I've kind of alluded to earlier,

00:30:13.825 --> 00:30:15.490
machine learning is going to be such a kind of

00:30:15.490 --> 00:30:17.605
an important building block

00:30:17.605 --> 00:30:22.120
of- that can be applied to any of the models that we kind of develop.

00:30:22.120 --> 00:30:27.700
So the central tenet in machine learning is you have data and you go to model,

00:30:27.700 --> 00:30:33.445
its main driver of a lot of su- successes in AI because it allows you to,

00:30:33.445 --> 00:30:35.230
in software engineering terms,

00:30:35.230 --> 00:30:37.495
move the complexity from code to data.

00:30:37.495 --> 00:30:38.680
Rather than having, you know,

00:30:38.680 --> 00:30:40.810
a million lines of code which is unmanageable,

00:30:40.810 --> 00:30:44.800
you have a lot of data which is collected in kind of

00:30:44.800 --> 00:30:47.440
a more natural way and a smaller amount of code that can

00:30:47.440 --> 00:30:50.590
operate on this data and this paradigm has really been,

00:30:50.590 --> 00:30:52.465
it's really been powerful.

00:30:52.465 --> 00:30:55.750
One thing to think about in terms of machine learning is that it,

00:30:55.750 --> 00:30:59.725
it is, requires a leap of faith, right.

00:30:59.725 --> 00:31:04.150
So you can go through the mechanics of down- downloading some machine learning code

00:31:04.150 --> 00:31:08.860
and you train them all but fundamentally it's about generalization, right.

00:31:08.860 --> 00:31:10.075
You have your data,

00:31:10.075 --> 00:31:11.710
you fit a model, uh,

00:31:11.710 --> 00:31:13.570
but you don't care about how it performs on that data;

00:31:13.570 --> 00:31:16.915
you care about how it performs on new experiences.

00:31:16.915 --> 00:31:19.450
And that leap of faith is something that's, um,

00:31:19.450 --> 00:31:23.155
I think gives machine learning its power but it's also a little bit,

00:31:23.155 --> 00:31:25.525
um, at first glance perhaps magical.

00:31:25.525 --> 00:31:29.995
Um, it turns out you can actually formalize a lot of this using,

00:31:29.995 --> 00:31:32.320
um, probability theory and,

00:31:32.320 --> 00:31:35.995
and statistics but that's kind of a topic for another time.

00:31:35.995 --> 00:31:38.425
Okay. So after we talk about machine learning,

00:31:38.425 --> 00:31:40.855
we're going to go back and talk about the,

00:31:40.855 --> 00:31:43.420
the simplest of models, right.

00:31:43.420 --> 00:31:45.430
So a reflex model is this.

00:31:45.430 --> 00:31:47.260
So here's a quiz.

00:31:47.260 --> 00:31:51.040
Okay. What is this animal? Okay, zebra.

00:31:51.040 --> 00:31:52.360
How did you get it so fast?

00:31:52.360 --> 00:31:56.710
Well, it's kind of a reflex, where your human visual system is so good,

00:31:56.710 --> 00:31:59.410
um, at, at doing these things without thinking.

00:31:59.410 --> 00:32:03.025
Um, and so reflex models are these, um,

00:32:03.025 --> 00:32:07.075
are models which just require a fixed set of computations.

00:32:07.075 --> 00:32:09.789
So examples like are linear classifiers,

00:32:09.789 --> 00:32:11.230
deep neural networks, um,

00:32:11.230 --> 00:32:15.340
and most of these models are the ones that people in machine learning um, use.

00:32:15.340 --> 00:32:17.065
Models is almost synonymous with,

00:32:17.065 --> 00:32:19.420
um, reflex on- in machine learning.

00:32:19.420 --> 00:32:21.265
The important thing that there's no feed for it.

00:32:21.265 --> 00:32:23.020
It just like you get your input bam,

00:32:23.020 --> 00:32:24.745
bam, bam, and here's your output.

00:32:24.745 --> 00:32:28.405
Okay, so that's, that's great because it's fast.

00:32:28.405 --> 00:32:32.725
But there's some problems that require a little bit more than that.

00:32:32.725 --> 00:32:35.605
Right. So for example here's another problem.

00:32:35.605 --> 00:32:38.505
Okay, quick, white to move. Where does she go?

00:32:38.505 --> 00:32:42.615
Okay, there's, there's probably like a few of you who are like chess geniuses,

00:32:42.615 --> 00:32:44.145
um, but for the rest of us,

00:32:44.145 --> 00:32:45.450
um, I have no idea.

00:32:45.450 --> 00:32:47.055
I don't know, wait, who's moving again?

00:32:47.055 --> 00:32:51.115
Um, so, so in these kind of situations,

00:32:51.115 --> 00:32:54.100
we need something perhaps a little bit more powerful than a reflex.

00:32:54.100 --> 00:32:57.970
We need agents that can kind of plan and think, um, ahead.

00:32:57.970 --> 00:33:00.610
So the idea behind state-based models is that we model

00:33:00.610 --> 00:33:04.645
the world as a set of states which capture any given situation like, uh,

00:33:04.645 --> 00:33:06.385
a position in a,

00:33:06.385 --> 00:33:12.325
in a game and actions that take us between states which correspond to things that,

00:33:12.325 --> 00:33:15.010
um, you can do in the, in this game.

00:33:15.010 --> 00:33:18.040
Um, so a lot of game applications fall in this as

00:33:18.040 --> 00:33:21.385
category of robotics, motion planning, navigation.

00:33:21.385 --> 00:33:25.435
Um, also some things that are might not be- you might think of,

00:33:25.435 --> 00:33:28.750
um, planning as such as gen- you know, generation, um.

00:33:28.750 --> 00:33:31.150
In natural language or generating an image,

00:33:31.150 --> 00:33:32.980
um, you are, uh,

00:33:32.980 --> 00:33:35.020
can be cast in this way as well.

00:33:35.020 --> 00:33:39.070
So there's three types of state-based models each of which we'll cover in,

00:33:39.070 --> 00:33:40.450
um, you know weeks of time.

00:33:40.450 --> 00:33:42.940
So search problems are the classic, uh,

00:33:42.940 --> 00:33:46.645
you control everything so you're just trying to fi- find the optimal path.

00:33:46.645 --> 00:33:48.700
There are cases where there's randomness.

00:33:48.700 --> 00:33:50.620
For example if you're trying to go from point A to point B,

00:33:50.620 --> 00:33:52.405
maybe there's traffic that you don't,

00:33:52.405 --> 00:33:54.040
you know, don't know about or, um,

00:33:54.040 --> 00:33:58.375
in a game there might be dice that are- die which are rolled, and, uh,

00:33:58.375 --> 00:34:01.450
there's a third category which are adversarial games which

00:34:01.450 --> 00:34:05.200
is cases where your playing an opponent who's actively trying to destroy you.

00:34:05.200 --> 00:34:06.685
So what are you gonna do about it?

00:34:06.685 --> 00:34:09.970
Um, so one of the games that we're gonna,

00:34:09.970 --> 00:34:11.740
uh, be talking about, uh,

00:34:11.740 --> 00:34:13.705
when we talk about games is Pac-Man;

00:34:13.705 --> 00:34:16.240
and one of the assignments is, um,

00:34:16.240 --> 00:34:20.065
actually building, um, a Pac-Man agent such as this.

00:34:20.065 --> 00:34:22.435
So, uh, while you're looking at this,

00:34:22.435 --> 00:34:26.380
think about how- what are the states and what are the actions and how would you go

00:34:26.380 --> 00:34:28.780
about you know devising a strategy for

00:34:28.780 --> 00:34:31.240
Pac-Man to eat all the dots and avoid all the ghosts?

00:34:31.240 --> 00:34:32.545
So that's something, uh,

00:34:32.545 --> 00:34:33.790
to maybe look forward to.

00:34:33.790 --> 00:34:35.110
There's also gonna be a competition.

00:34:35.110 --> 00:34:38.470
So we'll see how- who ends up at the top.

00:34:38.470 --> 00:34:42.580
Okay, so state-based models,

00:34:42.580 --> 00:34:46.765
um, are very powerful and a value to kind of have foresight.

00:34:46.765 --> 00:34:51.220
Um, but some problems are not really most naturally cast as state-based models.

00:34:51.220 --> 00:34:54.610
For example, you know, how many of you play Sudoku or have played it before?

00:34:54.610 --> 00:34:58.870
So as the goal of Sudoku is to fill in these, uh, um,

00:34:58.870 --> 00:35:01.525
blanks with numbers so that, um,

00:35:01.525 --> 00:35:04.810
every row and column and three-by-three sub-block has the digits 1 through 9.

00:35:04.810 --> 00:35:06.310
So there's a bunch of constraints.

00:35:06.310 --> 00:35:12.460
Um, and there's no kind of sense in which you have to do it in a certain order, right.

00:35:12.460 --> 00:35:17.500
Whereas the, the order in how you move in chess or something is,

00:35:17.500 --> 00:35:19.180
you know, pretty important.

00:35:19.180 --> 00:35:22.830
Um, so, so these type of problems, uh,

00:35:22.830 --> 00:35:28.390
are captured by these variable-based models where you kind of think about

00:35:28.390 --> 00:35:30.040
a solution to the problem as

00:35:30.040 --> 00:35:34.345
an assignment to the individual variables, under some constraints.

00:35:34.345 --> 00:35:36.040
So constraint satisfaction problems,

00:35:36.040 --> 00:35:37.390
we'll spent a week on that,

00:35:37.390 --> 00:35:39.250
um, these are hard constraints.

00:35:39.250 --> 00:35:41.410
For example two people can be- or

00:35:41.410 --> 00:35:44.230
a person can't be in the two places at once for example.

00:35:44.230 --> 00:35:47.050
Uh, there's also Bayesian networks which we'll talk about which

00:35:47.050 --> 00:35:50.425
are variable-based models with, uh, soft dependencies.

00:35:50.425 --> 00:35:53.500
For example if you're trying to track, um, you know,

00:35:53.500 --> 00:35:55.840
a car over time,

00:35:55.840 --> 00:35:57.865
these are the positions of the car.

00:35:57.865 --> 00:36:01.270
These variables represent the position of the cars and these,

00:36:01.270 --> 00:36:02.770
uh, E's represent, uh,

00:36:02.770 --> 00:36:08.620
the- the sensor readings of the position of the car at that particular position

00:36:08.620 --> 00:36:11.350
and inference looks like trying to figure out

00:36:11.350 --> 00:36:15.610
where the car was given all this kind of noisy sensor reading.

00:36:15.610 --> 00:36:18.985
So that's also gonna be another assignment where you're going to deal with.

00:36:18.985 --> 00:36:22.810
Okay. So finally, um, now we get to high-level.

00:36:22.810 --> 00:36:25.600
What's- so what is high-level intelligence here?

00:36:25.600 --> 00:36:27.655
Um, and I put logic here, um,

00:36:27.655 --> 00:36:30.505
for a reason that you'll see clear. Yeah, is there a question?

00:36:30.505 --> 00:36:34.180
The Sudoku, can you explain why it's not a state-based model?

00:36:34.180 --> 00:36:36.640
Yeah, so the question is why is not

00:36:36.640 --> 00:36:39.340
the- why is the Sudoku problem not a state-based model?

00:36:39.340 --> 00:36:43.015
Um, you can actually formulate this as a state-based model,

00:36:43.015 --> 00:36:47.260
um, by just thinking about the sequence of, uh, assignments.

00:36:47.260 --> 00:36:49.150
But it turns out that, um,

00:36:49.150 --> 00:36:52.030
you can formulate in a kind of

00:36:52.030 --> 00:36:55.195
more natural way as a variable-based model which allows you to,

00:36:55.195 --> 00:36:58.510
uh, take advantage of some kind of more efficient algorithm to solve it.

00:36:58.510 --> 00:37:02.470
Right, it's- think about these models as kind of different,

00:37:02.470 --> 00:37:04.720
um, analogy as like a programming language.

00:37:04.720 --> 00:37:07.090
So yes, you could write everything in you know

00:37:07.090 --> 00:37:11.200
C++ but sometimes writing in you know, Python or,

00:37:11.200 --> 00:37:16.615
or SQL for some things might be more- might be easier.

00:37:16.615 --> 00:37:17.900
Yeah.

00:37:17.900 --> 00:37:22.450
[inaudible] state based problem where you have both adversarial elements and an element of randomness?

00:37:22.450 --> 00:37:24.760
Yeah, so the question is how do you categorize

00:37:24.760 --> 00:37:27.760
state-based models where there is both randomness and an adversary?

00:37:27.760 --> 00:37:31.150
Um, we're also gonna talk about those as well.

00:37:31.150 --> 00:37:34.990
Um, and those would be- I,

00:37:34.990 --> 00:37:36.910
I would classify them as adversarial but

00:37:36.910 --> 00:37:39.100
there is also a random component that you have to deal with,

00:37:39.100 --> 00:37:41.260
games like backgammon. Yeah, question.

00:37:41.260 --> 00:37:58.870
[inaudible]

00:37:58.870 --> 00:38:00.895
Yeah, so the question is about whether, uh,

00:38:00.895 --> 00:38:04.270
some of these are more continuous and some of them are more discrete.

00:38:04.270 --> 00:38:07.735
Uh, I don't necessarily think of, uh,

00:38:07.735 --> 00:38:10.270
so a lot of the reflex models actually can work

00:38:10.270 --> 00:38:13.255
in continuous state spaces, for example images.

00:38:13.255 --> 00:38:17.200
Um, actually it's, it's almost a little bit of the opposite where, um,

00:38:17.200 --> 00:38:20.335
the logic-based models are in some sense more, you know,

00:38:20.335 --> 00:38:22.765
discrete but you can also have continuous elements,

00:38:22.765 --> 00:38:25.135
you know, in there, um, as well.

00:38:25.135 --> 00:38:26.740
Um, so in this class,

00:38:26.740 --> 00:38:28.900
we're mostly going to focus on kind of discrete objects

00:38:28.900 --> 00:38:32.060
because they're just going to be simpler to work with.

00:38:33.090 --> 00:38:36.880
Okay, so what is this logic?

00:38:36.880 --> 00:38:40.000
So the motivation here is that suppose you, um,

00:38:40.000 --> 00:38:43.240
wanted a little companion who, um,

00:38:43.240 --> 00:38:46.120
you could boss around and, um,

00:38:46.120 --> 00:38:47.725
help or help you do things,

00:38:47.725 --> 00:38:49.435
let's say; that's a better way to say it.

00:38:49.435 --> 00:38:52.375
Um, so you'd like to be able to say okay,

00:38:52.375 --> 00:38:54.730
you know, tell us some information, um,

00:38:54.730 --> 00:38:57.040
and then later you wanna be able to ask

00:38:57.040 --> 00:39:01.090
some questions and have the system be able to reply to you.

00:39:01.090 --> 00:39:06.355
Um, so, um, you know how- how would you go about doing this?

00:39:06.355 --> 00:39:09.610
One way you could think about is building a system that you

00:39:09.610 --> 00:39:13.030
can actually talk to using natural language, okay.

00:39:13.030 --> 00:39:14.470
So I'm actually going to show you a,

00:39:14.470 --> 00:39:16.990
a little demo, um, which, uh,

00:39:16.990 --> 00:39:20.110
is going to come up in the last assignment on logic;

00:39:20.110 --> 00:39:25.395
um, and well, let's see what you think about it.

00:39:25.395 --> 00:39:29.865
Uh, okay, so this is going to be a system that is, um,

00:39:29.865 --> 00:39:33.044
based on logic that I'm going to,

00:39:33.044 --> 00:39:37.230
um, tell the system a bunch of things and I'm going to ask some questions.

00:39:37.230 --> 00:39:40.610
So, um, I want you all to follow along and you see if you can,

00:39:40.610 --> 00:39:42.685
you know, play the role of the agents.

00:39:42.685 --> 00:39:45.130
Okay. So I'm going to teach you a few things like, um,

00:39:45.130 --> 00:39:48.280
Alice is a student, okay.

00:39:48.280 --> 00:39:49.855
So it says I learned something.

00:39:49.855 --> 00:39:52.435
Now let's, let's quiz,

00:39:52.435 --> 00:39:54.910
um, is Alice a student?

00:39:54.910 --> 00:39:57.625
Okay. Good. So that worked.

00:39:57.625 --> 00:40:00.865
Um, is Bob a student?

00:40:00.865 --> 00:40:05.860
What should the answer be? I don't know who's Bob. Um, okay.

00:40:05.860 --> 00:40:07.345
So now let's do, um,

00:40:07.345 --> 00:40:11.950
students are, uh, people.

00:40:11.950 --> 00:40:16.370
Um, Alice is not a person.

00:40:16.560 --> 00:40:18.670
I don't buy that [LAUGHTER] okay.

00:40:18.670 --> 00:40:21.235
So, um, okay it's,

00:40:21.235 --> 00:40:22.840
you know, it's doing some reasoning, right?

00:40:22.840 --> 00:40:26.380
It's using logic, it's not, uh, just, um.

00:40:26.380 --> 00:40:28.600
Okay. So now, let's do, um,

00:40:28.600 --> 00:40:32.035
Alice is from Phoenix.

00:40:32.035 --> 00:40:34.990
Phoenix is a hot city.

00:40:34.990 --> 00:40:36.580
I know because I've lived there.

00:40:36.580 --> 00:40:39.385
Um, cities are places,

00:40:39.385 --> 00:40:43.210
and if it is snowing,

00:40:43.210 --> 00:40:47.830
uh, it is, um, then it is cold.

00:40:47.830 --> 00:40:51.565
Okay, got it. So, um,

00:40:51.565 --> 00:40:57.250
is it snowing? I don't know.

00:40:57.250 --> 00:41:00.055
Um, so how about this?

00:41:00.055 --> 00:41:01.600
Okay. So if, um,

00:41:01.600 --> 00:41:05.200
a person is from a hot place and it is cold,

00:41:05.200 --> 00:41:08.545
then she is not happy, okay.

00:41:08.545 --> 00:41:11.470
True. Right, um.

00:41:11.470 --> 00:41:13.750
I guess those of you who have spent all your

00:41:13.750 --> 00:41:16.330
live in California would maybe appreciate this.

00:41:16.330 --> 00:41:20.330
But, um, okay, so ho- is it snowing now?

00:41:21.090 --> 00:41:23.905
How many of you say yeah, it's snowing?

00:41:23.905 --> 00:41:27.670
How many say no? You don't know? Okay.

00:41:27.670 --> 00:41:31.090
[inaudible]

00:41:31.090 --> 00:41:39.400
Ah, ah, [LAUGHTER] um, how about if I say Alice is, ah, happy.

00:41:39.400 --> 00:41:42.565
Okay, so is it snowing now?

00:41:42.565 --> 00:41:44.725
No, it should be no. Okay. So you,

00:41:44.725 --> 00:41:45.895
you guys were able to do this.

00:41:45.895 --> 00:41:49.810
Okay. So this is kind of an example of a interaction which, um,

00:41:49.810 --> 00:41:52.525
if you think about it has is ve-

00:41:52.525 --> 00:41:56.395
very different from where you would see kind of in a typical,

00:41:56.395 --> 00:41:59.710
um, you know, ML system where you have to show it millions of

00:41:59.710 --> 00:42:02.905
examples of one particular thing and it can do a kind of one task.

00:42:02.905 --> 00:42:07.195
This is much more of a very open-ended set of,

00:42:07.195 --> 00:42:10.080
um, I wish to say that the,

00:42:10.080 --> 00:42:12.600
the experiences are super rich but they're definitely diverse.

00:42:12.600 --> 00:42:15.435
I teach- I just give one statement.

00:42:15.435 --> 00:42:19.200
I say it once and then all of a sudden it has all the ramifications

00:42:19.200 --> 00:42:21.510
and kind of consequences that

00:42:21.510 --> 00:42:24.610
built in and it kind of understands in a kind of a deeper level.

00:42:24.610 --> 00:42:26.320
Of course this is based on,

00:42:26.320 --> 00:42:27.610
you know, logic systems.

00:42:27.610 --> 00:42:31.420
Um, so it is brittle but this is kind of just a proof of concept

00:42:31.420 --> 00:42:35.890
to give you a taste of what I mean when I say logic.

00:42:35.890 --> 00:42:38.995
So, ah, these systems need to be able to digest

00:42:38.995 --> 00:42:42.220
this heterogeneous information and reason deeply with that information.

00:42:42.220 --> 00:42:44.035
And we'll see kind of how, um,

00:42:44.035 --> 00:42:46.795
logic systems can do that.

00:42:46.795 --> 00:42:53.305
Okay. So that completes the tour of the topics of this class.

00:42:53.305 --> 00:42:58.810
Um, now I want to spend a little bit of time on course logistics.

00:42:58.810 --> 00:43:03.910
Uh, so I wanna- all the details here are online.

00:43:03.910 --> 00:43:06.970
So I'm not going to be complete in my coverage, um,

00:43:06.970 --> 00:43:10.900
but I just wanna give you a general sense of what's going on here.

00:43:10.900 --> 00:43:13.885
Okay. So what are we trying to do in this course?

00:43:13.885 --> 00:43:17.890
Um, so prerequisites, um,

00:43:17.890 --> 00:43:22.915
there's programming, um, discrete math and, ah, probability.

00:43:22.915 --> 00:43:25.255
So you need t be able to code and you need to be able to, um,

00:43:25.255 --> 00:43:27.325
do some math and,

00:43:27.325 --> 00:43:29.020
uh, some kind of basic proofs.

00:43:29.020 --> 00:43:31.960
Right? So these are the classes that are, um,

00:43:31.960 --> 00:43:34.525
required or at least recommended that you-

00:43:34.525 --> 00:43:37.810
or if you have some equivalent experience that's, you know, fine too.

00:43:37.810 --> 00:43:41.950
Um, and what we- what should you hope to get out of this course?

00:43:41.950 --> 00:43:45.850
Right. So one had- the course is meant to be giving

00:43:45.850 --> 00:43:50.065
you a set of tools using the modeling inference learning paradigm.

00:43:50.065 --> 00:43:54.040
It gives you a set of tools and a way of thinking about problems that hopefully will

00:43:54.040 --> 00:43:56.020
be really useful for you when you go

00:43:56.020 --> 00:43:58.210
out in the world and try to solve real world problems.

00:43:58.210 --> 00:44:02.800
Um, and also by- as a side product I also want all of you

00:44:02.800 --> 00:44:05.035
to be more proficient at

00:44:05.035 --> 00:44:08.050
your math and programming because those are kind of the core elements that,

00:44:08.050 --> 00:44:10.779
ah, enable you to do kind of interesting,

00:44:10.779 --> 00:44:12.500
you know, things in AI.

00:44:12.500 --> 00:44:14.760
So a lot of AI and you, you read about it,

00:44:14.760 --> 00:44:18.480
it's very flashy but really the foundations are still,

00:44:18.480 --> 00:44:22.110
um, just you know math and programming in some sense.

00:44:22.110 --> 00:44:25.690
Okay. So the coursework is homeworks,

00:44:25.690 --> 00:44:27.190
exam, and a project.

00:44:27.190 --> 00:44:29.065
That's what you have to do, um,

00:44:29.065 --> 00:44:30.535
Homeworks, there's eight homeworks.

00:44:30.535 --> 00:44:34.420
Each homework is a mix of writing- written and programming problems centered on

00:44:34.420 --> 00:44:38.995
a particular application covering one particular type of model essentially.

00:44:38.995 --> 00:44:41.920
Um, like I mentioned before there's a competition for extra credit.

00:44:41.920 --> 00:44:46.105
There's also some extra credit problems in the, in the homeworks,

00:44:46.105 --> 00:44:49.060
um, and when you submit code,

00:44:49.060 --> 00:44:51.805
we're gonna run- we have an auto-grader that runs.

00:44:51.805 --> 00:44:55.300
It's gonna run on all the test cases but you get a feedback of only a subset.

00:44:55.300 --> 00:44:57.250
So you can, um,

00:44:57.250 --> 00:44:58.945
it's like, you know, in machine learning,

00:44:58.945 --> 00:45:00.460
you have a train set, and you have a test set.

00:45:00.460 --> 00:45:02.080
So don't train on your test set.

00:45:02.080 --> 00:45:03.730
[LAUGHTER] Okay.

00:45:03.730 --> 00:45:07.790
So um, the exam is,

00:45:08.070 --> 00:45:13.405
ah, testing your ability to use the knowledge that you learn to solve new problems.

00:45:13.405 --> 00:45:15.490
Right. So there's, um,

00:45:15.490 --> 00:45:18.250
I think it's worth taking a look at exam because this,

00:45:18.250 --> 00:45:20.530
this kind of surprises people every- the exam is

00:45:20.530 --> 00:45:23.920
a little bit different than the types of problems that you see on,

00:45:23.920 --> 00:45:27.475
on the homework and there are kind of more problem, you know, solving.

00:45:27.475 --> 00:45:29.530
So the exam isn't going to be like a multiple choice like,

00:45:29.530 --> 00:45:31.930
okay, you know, um,

00:45:31.930 --> 00:45:37.045
you know, when was Perceptrons published or something like that.

00:45:37.045 --> 00:45:39.370
It's gonna be, here's a real life problem.

00:45:39.370 --> 00:45:42.430
How do you model it and how do you come up with a solution?

00:45:42.430 --> 00:45:43.990
Um, they're all going to be written.

00:45:43.990 --> 00:45:46.390
It's closed book except for you have a one page of

00:45:46.390 --> 00:45:49.160
notes and this is a great opportunity to actually,

00:45:49.160 --> 00:45:52.485
um, review all the material and actually learn the ah,

00:45:52.485 --> 00:45:54.570
the content in the class.

00:45:54.570 --> 00:45:58.665
Um, so the project I think is a,

00:45:58.665 --> 00:46:01.065
a really good opportunity to take

00:46:01.065 --> 00:46:04.230
all the things that we've been talking about in the class and,

00:46:04.230 --> 00:46:09.420
um, try to find something you really care about and try to apply it.

00:46:09.420 --> 00:46:14.930
Work in groups of three and I really recommend finding a group early,

00:46:14.930 --> 00:46:19.750
um, and as I emphasize it's your responsibility to find, you know, a good group.

00:46:19.750 --> 00:46:24.820
Right? Um, don't come to us later like one week before the project deadline and say,

00:46:24.820 --> 00:46:26.980
"Oh, you know, my group members they,

00:46:26.980 --> 00:46:28.900
um, they ditched me," or something.

00:46:28.900 --> 00:46:30.055
We really try to,

00:46:30.055 --> 00:46:36.145
try to nail this down use Piazza to- or your other social networks to find a good group.

00:46:36.145 --> 00:46:39.850
So throughout the quarter there's going to be these milestones for the projects.

00:46:39.850 --> 00:46:44.215
So, um, to prevent you guys from procrastinating into the very end, um,

00:46:44.215 --> 00:46:48.835
so there's gonna be a proposal where you try and brainstorm some ideas, progress report,

00:46:48.835 --> 00:46:52.315
a poster session which is actually a whole week before the final report is due,

00:46:52.315 --> 00:46:54.550
um, and the project is very open.

00:46:54.550 --> 00:46:56.260
So this can be, um,

00:46:56.260 --> 00:47:00.500
really liberating but also might be a little bit daunting.

00:47:00.500 --> 00:47:05.170
Um, we will hopefully give you a lot of structure in terms of saying okay,

00:47:05.170 --> 00:47:06.430
how do you define your task?

00:47:06.430 --> 00:47:08.050
How do you implement different,

00:47:08.050 --> 00:47:09.760
um, baselines or oracles?

00:47:09.760 --> 00:47:10.840
Which I'll explain later.

00:47:10.840 --> 00:47:12.445
How do you evaluate? How do you,

00:47:12.445 --> 00:47:14.365
um, analyze what you've done?

00:47:14.365 --> 00:47:18.250
And each of you will- each project group will be assigned a CA mentor,

00:47:18.250 --> 00:47:20.215
ah, to help you, ah,

00:47:20.215 --> 00:47:23.080
through the process and you're always welcome to come to

00:47:23.080 --> 00:47:26.860
my office hours or Dorsa's, or any of the CAs to get additional, um,

00:47:26.860 --> 00:47:31.120
help either brainstorming or figuring out what the next step is.

00:47:31.120 --> 00:47:34.165
Ah, some policies, ah,

00:47:34.165 --> 00:47:36.714
all assignments will be submitted on Gradescope,

00:47:36.714 --> 00:47:39.505
um, there are seven total late days

00:47:39.505 --> 00:47:43.735
you can use, and most two per assignment. After that there's no credit.

00:47:43.735 --> 00:47:48.730
Um, ah, we're gonna use Piazza for all communication so don't email us directly.

00:47:48.730 --> 00:47:50.785
Leave a post on Piazza.

00:47:50.785 --> 00:47:53.500
If- I encourage you to make it public if it's,

00:47:53.500 --> 00:47:55.240
it's not sensitive, but if it's, you know,

00:47:55.240 --> 00:47:57.250
personal, then obviously make it private,

00:47:57.250 --> 00:47:59.665
um, and try to help each other.

00:47:59.665 --> 00:48:04.045
We'll actually award some extra credit for students who help answer,

00:48:04.045 --> 00:48:07.060
um, other student's questions.

00:48:07.060 --> 00:48:09.610
So all of the details are on the course website.

00:48:09.610 --> 00:48:14.905
Okay. So one last thing and it's really important and that's the Honor Code.

00:48:14.905 --> 00:48:17.110
Okay. So especially if you're,

00:48:17.110 --> 00:48:20.050
um, you know, you've probably heard this if you've been at Stanford.

00:48:20.050 --> 00:48:23.860
If you haven't, then I wanna really kind of make this clear.

00:48:23.860 --> 00:48:29.575
So I encourage you all to have- collaborate, discuss together.

00:48:29.575 --> 00:48:32.740
But when you- when it comes to actually the homeworks,

00:48:32.740 --> 00:48:36.820
you have to write up your homework and code it independently.

00:48:36.820 --> 00:48:39.340
So you shouldn't be looking at someone's writeup.

00:48:39.340 --> 00:48:41.665
You shouldn't be looking at their code.

00:48:41.665 --> 00:48:45.190
Um, and you definitely shouldn't be copying code off of GitHub.

00:48:45.190 --> 00:48:47.590
Um, um, that's hopefully should be,

00:48:47.590 --> 00:48:49.540
you know, obvious and maybe less obvious,

00:48:49.540 --> 00:48:54.340
you should not- please do not post your homework assignments on GitHub.

00:48:54.340 --> 00:48:57.790
I know you're probably proud of the fact that your Pac-Man agent is doing really well

00:48:57.790 --> 00:49:03.100
but please don't post on GitHub because then that's going to be our Honor Code violation.

00:49:03.100 --> 00:49:06.205
Um, when debugging, um,

00:49:06.205 --> 00:49:08.395
with- if you're working together,

00:49:08.395 --> 00:49:10.870
it's fine to as long as

00:49:10.870 --> 00:49:13.450
it's kind of looking at input-output behavior so you can say to your partner,

00:49:13.450 --> 00:49:15.040
"Hey, I put in this,

00:49:15.040 --> 00:49:17.230
um, input to my test case and I'm getting a 3.

00:49:17.230 --> 00:49:20.185
What are you getting?" So that's fine but you can't.

00:49:20.185 --> 00:49:22.795
Remember don't look at each other's code.

00:49:22.795 --> 00:49:25.690
Um, and to enforce this, we're gonna be running MOSS,

00:49:25.690 --> 00:49:30.370
which is a software program that looks for code duplication, um, to,

00:49:30.370 --> 00:49:32.395
to make sure that,

00:49:32.395 --> 00:49:34.975
ah, the rules are being followed and,

00:49:34.975 --> 00:49:39.880
you know, changing one variable name is- or you'll be so- anyway enough said.

00:49:39.880 --> 00:49:42.895
[LAUGHTER] Just don't, don't, don't do that.

00:49:42.895 --> 00:49:45.730
Okay? Any questions about this?

00:49:45.730 --> 00:49:48.640
I wanna make sure this is important or about any of those logistics. Yeah.

00:49:48.640 --> 00:49:50.680
[inaudible]

00:49:50.680 --> 00:49:51.925
The final project, ah,

00:49:51.925 --> 00:49:54.170
you can put on GitHub.

00:49:55.570 --> 00:49:59.780
Yeah.

00:49:59.780 --> 00:50:02.990
Yeah.

00:50:02.990 --> 00:50:04.925
Yeah, private GitHub repos,

00:50:04.925 --> 00:50:10.880
uh, is fine. Yeah, question in the back?

00:50:10.880 --> 00:50:14.210
Is it necessary to have a group or can you do a solo project?

00:50:14.210 --> 00:50:16.490
Uh, the question is can you,

00:50:16.490 --> 00:50:17.990
can you do a solo project?

00:50:17.990 --> 00:50:19.430
You can do a solo project,

00:50:19.430 --> 00:50:20.840
you can do a project with two people,

00:50:20.840 --> 00:50:22.910
or you can do a project with three.

00:50:22.910 --> 00:50:27.125
I would encourage you to try to work in, uh,

00:50:27.125 --> 00:50:31.460
groups of three because you'll be able to do more as a group,

00:50:31.460 --> 00:50:33.275
and there is definitely,

00:50:33.275 --> 00:50:36.110
uh, you know, it, it, it's not like if you do

00:50:36.110 --> 00:50:39.815
a solo project we'll be expecting like one third of the, the work.

00:50:39.815 --> 00:50:44.390
So okay.

00:50:44.390 --> 00:50:48.035
Anything else? All right.

00:50:48.035 --> 00:50:52.625
Okay. So in the fi- final section,

00:50:52.625 --> 00:50:56.540
I want to actually delve into s- some technical details.

00:50:56.540 --> 00:51:01.385
Um, and one thing we're going to focus on right now is, um,

00:51:01.385 --> 00:51:06.575
the, kind of inference and learning components of, of this course.

00:51:06.575 --> 00:51:09.020
So I'm going to talk about how you can

00:51:09.020 --> 00:51:12.095
approach these through the lens of, you know, optimization.

00:51:12.095 --> 00:51:13.625
So this is going to be,

00:51:13.625 --> 00:51:15.980
uh, it might be a review for some of you but hopefully,

00:51:15.980 --> 00:51:17.645
it's gonna be a, a good,

00:51:17.645 --> 00:51:21.890
um, you know, way to get everyone on the same page.

00:51:21.890 --> 00:51:24.275
Okay. So what is optimization?

00:51:24.275 --> 00:51:26.975
There's two flavors of optimization that we care about.

00:51:26.975 --> 00:51:29.105
There's, uh, Discrete Optimization,

00:51:29.105 --> 00:51:31.880
where you're trying to find the best, uh, discrete object.

00:51:31.880 --> 00:51:34.685
For example, you're trying to find the best, uh,

00:51:34.685 --> 00:51:39.785
path or the path P that minimizes the cost of that path.

00:51:39.785 --> 00:51:44.885
Um, we're going to talk about one algorithmic tool, um,

00:51:44.885 --> 00:51:49.235
based on Dynamic Programming which is a very powerful way of solving these,

00:51:49.235 --> 00:51:51.725
um, complex optimization problems.

00:51:51.725 --> 00:51:53.975
Um, and the key, you know,

00:51:53.975 --> 00:51:58.895
property here is that the set of paths is huge and you can't just,

00:51:58.895 --> 00:52:02.270
uh, trial them and compute the cost and choose the best one.

00:52:02.270 --> 00:52:04.190
So you gonna have to choose something clever.

00:52:04.190 --> 00:52:11.420
The second brand of optimization is continuous optimization and formally this is just

00:52:11.420 --> 00:52:14.030
finding the best of vector of

00:52:14.030 --> 00:52:18.325
real numbers that satisfies or minimizes some objective function.

00:52:18.325 --> 00:52:22.570
So a typical place this shows up is in learning where you define, uh,

00:52:22.570 --> 00:52:26.080
objective function like the training error and you're trying to

00:52:26.080 --> 00:52:30.730
find a weight vector W. So this notation just means it's a list of numbers,

00:52:30.730 --> 00:52:33.955
D numbers that minimizes the training error.

00:52:33.955 --> 00:52:38.275
And we're going to show that gradient descent is, uh, uh,

00:52:38.275 --> 00:52:42.105
easy and a surprisingly effective way of solving these,

00:52:42.105 --> 00:52:44.720
um, continuous optimization problems.

00:52:44.720 --> 00:52:48.530
Okay. So to introduce these two ideas,

00:52:48.530 --> 00:52:50.750
I'm going to look at two, um,

00:52:50.750 --> 00:52:53.210
problems and trying to kind of work through them.

00:52:53.210 --> 00:52:56.330
So this might be also a good, um, you know,

00:52:56.330 --> 00:53:00.305
way to think about how you might go approach a,

00:53:00.305 --> 00:53:01.475
you know, homework problems.

00:53:01.475 --> 00:53:05.300
And I'll try to kind of talk you through this, um, in a bit more detail.

00:53:05.300 --> 00:53:07.505
Okay, so the first problem is,

00:53:07.505 --> 00:53:10.190
um, you know, computing edit distance.

00:53:10.190 --> 00:53:13.640
Um, and this might not look,

00:53:13.640 --> 00:53:16.205
you know, like an AI problem, but a lot of, ah,

00:53:16.205 --> 00:53:18.530
AI problems have this as kind of a, you know,

00:53:18.530 --> 00:53:21.215
building block if you wanted to do some sort of matching between,

00:53:21.215 --> 00:53:25.295
um, you know, two words or two, um, biological sequences.

00:53:25.295 --> 00:53:28.040
So the input is you're given two strings.

00:53:28.040 --> 00:53:33.095
Um, we're gonna start writing over here on the board just to work this out.

00:53:33.095 --> 00:53:35.135
So given two strings, um,

00:53:35.135 --> 00:53:37.865
S and T. Um,

00:53:37.865 --> 00:53:40.415
so for example, um,

00:53:40.415 --> 00:53:45.635
a cat and um, the cats.

00:53:45.635 --> 00:53:51.200
Okay. So these are two strings and you wanna find the minimum number of edits that is

00:53:51.200 --> 00:53:56.989
needed to take transform S into T. And by edits I mean you can insert,

00:53:56.989 --> 00:53:59.660
um, a character like you can insert S,

00:53:59.660 --> 00:54:01.700
you can delete characters,

00:54:01.700 --> 00:54:05.390
I can delete this A and you can substitute one character for another.

00:54:05.390 --> 00:54:08.930
So you can replace this A with a T. Okay.

00:54:08.930 --> 00:54:10.670
Um, so here's some examples.

00:54:10.670 --> 00:54:12.380
What's the edit distance of cat and cat?

00:54:12.380 --> 00:54:13.820
It's 0, you don't have to do anything.

00:54:13.820 --> 00:54:15.110
Cat and dog is 3,

00:54:15.110 --> 00:54:16.430
cat and at is 1,

00:54:16.430 --> 00:54:19.745
you insert the A or insert a C. Um,

00:54:19.745 --> 00:54:22.095
cat and cat is 1, um,

00:54:22.095 --> 00:54:25.870
and a cat and the cats is 4.

00:54:25.870 --> 00:54:30.430
Okay. So the challenge here is that there are,

00:54:30.430 --> 00:54:36.240
ah, quite a different number of ways to insert and delete.

00:54:36.240 --> 00:54:38.900
Right, so if you have a string of- that's very

00:54:38.900 --> 00:54:43.130
long there's just way too many things to like just try out all of them.

00:54:43.130 --> 00:54:45.335
Okay, so then, how do we,

00:54:45.335 --> 00:54:46.550
how do we go about,

00:54:46.550 --> 00:54:49.160
um, coming up with a solution?

00:54:49.160 --> 00:54:53.990
So any ideas? Yeah.

00:54:53.990 --> 00:55:00.680
[inaudible] simplify the output in terms of saying that

00:55:00.680 --> 00:55:04.610
the substitution tells us we considered [inaudible] deletion peoples who considered

00:55:04.610 --> 00:55:09.080
a substitution or vice-versa by saying like an empty character.

00:55:09.080 --> 00:55:11.765
Yeah, yeah. So let's try to simplify [NOISE] the,

00:55:11.765 --> 00:55:12.965
the, the problem a bit.

00:55:12.965 --> 00:55:17.150
And building up on your what you, um, what was said.

00:55:17.150 --> 00:55:22.550
So, um, one thing to note is that okay,

00:55:22.550 --> 00:55:24.890
where so the general principle,

00:55:24.890 --> 00:55:27.360
let me just write the general principle,

00:55:28.690 --> 00:55:30.950
um, is to, you know,

00:55:30.950 --> 00:55:33.890
reduce the problem to

00:55:33.890 --> 00:55:39.590
a simpler problem because then you can hopefully solve- it is easier to solve,

00:55:39.590 --> 00:55:43.775
and then you can maybe keep on doing that until you get something that's trivial.

00:55:43.775 --> 00:55:47.210
Okay. So there's maybe two observations we can make.

00:55:47.210 --> 00:55:48.965
One is that well,

00:55:48.965 --> 00:55:51.815
we're technically saying we can, um, you know,

00:55:51.815 --> 00:55:56.705
insert into S right but if we insert into S,

00:55:56.705 --> 00:55:59.825
it makes the problem kind of larger in some sense, right?

00:55:59.825 --> 00:56:01.445
I mean that's not, that's not good.

00:56:01.445 --> 00:56:02.975
That's not reducing the problem.

00:56:02.975 --> 00:56:06.725
But, but whenever we insert into S, um,

00:56:06.725 --> 00:56:08.930
we probably want to insert things which are in

00:56:08.930 --> 00:56:11.330
T. We wanna like cancel something out, right?

00:56:11.330 --> 00:56:13.775
So we wouldn't insert a K there for any reason.

00:56:13.775 --> 00:56:17.120
We probably wanna insert a S in which case no S

00:56:17.120 --> 00:56:20.780
matches that and then we've reduced that problem, right?

00:56:20.780 --> 00:56:23.135
So we can actually think about, you know,

00:56:23.135 --> 00:56:31.220
inserting into S to S as equivalent to kind of deleting from,

00:56:31.220 --> 00:56:37.220
um, from T. Okay, does that make sense?

00:56:37.220 --> 00:56:43.835
All right. So another observation we can make is that,

00:56:43.835 --> 00:56:46.430
you know, we can start inserting anywhere.

00:56:46.430 --> 00:56:49.235
We can start inserting here and then jump over here and to this.

00:56:49.235 --> 00:56:52.380
But this just introduces a lot of, um,

00:56:52.380 --> 00:56:56.750
you know, ways of doing it which all kind of result in the same answer.

00:56:56.750 --> 00:57:00.320
So why don't we just start more systematically at

00:57:00.320 --> 00:57:04.130
one end and then just proceed and try to chisel-off the problem,

00:57:04.130 --> 00:57:06.740
um, kind of let's say from the end.

00:57:06.740 --> 00:57:14.580
Okay, so start at the end?

00:57:16.510 --> 00:57:27.410
Okay, so, so now we have this problem and to draw a problem in a little box here.

00:57:27.410 --> 00:57:30.860
Um, so let's start at the end. Yeah, question.

00:57:30.860 --> 00:57:34.490
What's the reasoning used to reach that principle start at the end?

00:57:34.490 --> 00:57:36.020
[NOISE].

00:57:36.020 --> 00:57:40.250
[NOISE] the question is why are we starting at the end as oppo- well,

00:57:40.250 --> 00:57:43.310
the idea is that if you start at the end then you

00:57:43.310 --> 00:57:46.205
have kind of a more systematic and consistent way of,

00:57:46.205 --> 00:57:47.765
you know, reducing the problem.

00:57:47.765 --> 00:57:52.400
So you don't have to think about all the permutations of where I can delete and substitute.

00:57:52.400 --> 00:57:54.080
Why is it more systematic to go from

00:57:54.080 --> 00:57:56.180
the right to the left than from the left to the right?

00:57:56.180 --> 00:57:57.635
We can also do it left to right.

00:57:57.635 --> 00:58:01.595
So the end or the start is both fine.

00:58:01.595 --> 00:58:06.035
This is just- I just picked the end. Yeah.

00:58:06.035 --> 00:58:10.085
Are we not starting at the end and then give us the optimal strategy?

00:58:10.085 --> 00:58:13.190
Yeah, the question is how do we know that starting,

00:58:13.190 --> 00:58:16.820
um, at one end can give you the optimal strategy?

00:58:16.820 --> 00:58:19.550
Um, so, you know,

00:58:19.550 --> 00:58:23.735
if you wanted to prove this more rigorously there's some work but,

00:58:23.735 --> 00:58:25.175
um, I'll just try to give you a,

00:58:25.175 --> 00:58:26.585
you know, an intuitive answer.

00:58:26.585 --> 00:58:29.855
Um, suppose you didn't start at the end,

00:58:29.855 --> 00:58:33.335
and you just made a sequence of steps like I insert here,

00:58:33.335 --> 00:58:36.725
I delete here, and then I went over here and um,

00:58:36.725 --> 00:58:39.410
did all those operations to S. I

00:58:39.410 --> 00:58:42.260
could have equivalently also just sorted those by, you know,

00:58:42.260 --> 00:58:45.290
where it was happening and then just proceeded from

00:58:45.290 --> 00:58:49.100
one end to the other, and I would arrive at the exact same answer.

00:58:49.100 --> 00:58:50.720
So without loss of generality,

00:58:50.720 --> 00:58:55.430
I can start at that. Any other questions?

00:59:00.590 --> 00:59:03.495
Okay. So yeah.

00:59:03.495 --> 00:59:07.200
Instead of doing this wouldn't the more viable [NOISE] approach be that

00:59:07.200 --> 00:59:11.490
trying to recognize some patterns instead of doing this.

00:59:11.490 --> 00:59:15.990
I think between the two strings "s" and "t" like some form of- some sort of

00:59:15.990 --> 00:59:20.820
[NOISE] pattern [inaudible] string.

00:59:20.820 --> 00:59:24.150
Yeah. So the question is, maybe you can recognize some patterns.

00:59:24.150 --> 00:59:25.575
Uh, it's like okay, oh, cat.

00:59:25.575 --> 00:59:28.380
That's- that's- maybe those should be lined up.

00:59:28.380 --> 00:59:32.820
Um, I guess these examples are chosen so that these patterns exist,

00:59:32.820 --> 00:59:35.880
but we want to solve the problem for cases where,

00:59:35.880 --> 00:59:37.740
um, the pattern might not be obvious.

00:59:37.740 --> 00:59:41.010
So it could be- we want to work it for- it to work for all strings.

00:59:41.010 --> 00:59:42.345
Maybe there is no pattern,

00:59:42.345 --> 00:59:47.655
and we still would want to- kind of an efficient algorithm to do it. Yeah.

00:59:47.655 --> 00:59:50.385
Can't we just like use dynamic programming?

00:59:50.385 --> 00:59:51.945
Like we go one by one,

00:59:51.945 --> 00:59:53.610
there was always like [inaudible] -

00:59:53.610 --> 00:59:54.035
Yeah.

00:59:54.035 --> 00:59:57.525
Either we're doing, um, substitution,

00:59:57.525 --> 01:00:02.235
or, um, otherwise it's like the same character. Or we have to insert-

01:00:02.235 --> 01:00:02.835
Yeah.

01:00:02.835 --> 01:00:04.455
- um, and then we keep going,

01:00:04.455 --> 01:00:06.960
and you just like [NOISE] remember

01:00:06.960 --> 01:00:09.930
each like to- to strings that we have at one point-

01:00:09.930 --> 01:00:10.360
Uh-huh.

01:00:10.360 --> 01:00:12.810
-so that if we calculated that we don't have to do it again.

01:00:12.810 --> 01:00:13.335
Yeah. Yeah.

01:00:13.335 --> 01:00:14.130
That's it. Yeah.

01:00:14.130 --> 01:00:15.795
Yeah. Yeah. Great idea.

01:00:15.795 --> 01:00:17.400
Let's do dynamic programming.

01:00:17.400 --> 01:00:21.555
Um, so that's what I'm kind of trying to build up from- uh, build up to.

01:00:21.555 --> 01:00:27.690
Okay so, um, so if you look at this- so dynamic programming is a kind of

01:00:27.690 --> 01:00:30.630
a general technique that essentially allows you

01:00:30.630 --> 01:00:33.885
to express this more complicated problem in terms of a simpler problem.

01:00:33.885 --> 01:00:35.340
Uh, so let's start with this problem.

01:00:35.340 --> 01:00:36.525
If we start at the end,

01:00:36.525 --> 01:00:38.475
um, if the two match then,

01:00:38.475 --> 01:00:41.325
well we can just immediately, um, you know,

01:00:41.325 --> 01:00:44.820
delete these two and that's- it's gonna be the same, right?

01:00:44.820 --> 01:00:47.265
So we can get- we are gonna get some free rides there.

01:00:47.265 --> 01:00:49.020
Okay, but when they differ,

01:00:49.020 --> 01:00:52.500
um, now we have many options.

01:00:52.500 --> 01:00:54.795
So what we could- what could we do?

01:00:54.795 --> 01:00:59.640
Well, we could, um, um, you know substitute.

01:00:59.640 --> 01:01:02.205
Okay, we can change the "t" to an "s".

01:01:02.205 --> 01:01:03.990
So what does that leave us with?

01:01:03.990 --> 01:01:05.940
So I can do a cat,

01:01:05.940 --> 01:01:12.375
[NOISE] "t" is the- the cat,

01:01:12.375 --> 01:01:18.780
the- [NOISE] Okay, so I can substitute.

01:01:18.780 --> 01:01:25.230
[NOISE] Um, [NOISE] okay.

01:01:25.230 --> 01:01:27.000
Um, what else can I do?

01:01:27.000 --> 01:01:29.970
[NOISE] Someone say something I can do.

01:01:29.970 --> 01:01:34.710
[NOISE] So I can insert,

01:01:34.710 --> 01:01:37.950
um, insert where into-

01:01:37.950 --> 01:01:40.380
[OVERLAPPING]

01:01:40.380 --> 01:01:42.120
So I can insert an "s", right?

01:01:42.120 --> 01:01:42.480
Yes. [NOISE]

01:01:42.480 --> 01:01:43.590
But that's the same as, you know,

01:01:43.590 --> 01:01:45.165
[inaudible] deleting from "t".

01:01:45.165 --> 01:01:48.465
So by, uh- you can basically also just delete this "s".

01:01:48.465 --> 01:01:53.940
Um, so this is our cat,

01:01:53.940 --> 01:02:01.360
[NOISE] and I deleted this "s" from "t".

01:02:02.060 --> 01:02:04.590
Okay, so this is,

01:02:04.590 --> 01:02:08.025
um, let's call it, uh, you know,

01:02:08.025 --> 01:02:17.220
um, I guess let's call this insertion- it's technically insertion [NOISE].

01:02:17.220 --> 01:02:18.780
And then finally what can I do?

01:02:18.780 --> 01:02:28.515
[NOISE] I can also remove "t".

01:02:28.515 --> 01:02:36.000
So [NOISE] a, ca, the, cats.

01:02:36.000 --> 01:02:37.080
Okay, so this is delete.

01:02:37.080 --> 01:02:40.350
[NOISE] And right now you're probably looking at this like,

01:02:40.350 --> 01:02:41.460
well, obviously, you know,

01:02:41.460 --> 01:02:42.825
you sho- you should do this one.

01:02:42.825 --> 01:02:44.460
But in general it's hard to tell.

01:02:44.460 --> 01:02:46.515
What if I just give you some arbitrary strings,

01:02:46.515 --> 01:02:49.050
you know, who knows what the right answer is.

01:02:49.050 --> 01:02:54.750
Um, so in general how do you pick? Yeah.

01:02:54.750 --> 01:02:58.020
In the second one, the "t" is supposed to be for cats.

01:02:58.020 --> 01:03:00.420
[NOISE] [inaudible]

01:03:00.420 --> 01:03:01.200
You mean this one?

01:03:01.200 --> 01:03:01.545
Yeah.

01:03:01.545 --> 01:03:05.040
So here I inserted an "s", right?

01:03:05.040 --> 01:03:07.950
But then because there's two s's here,

01:03:07.950 --> 01:03:11.010
I just canceled them out and [NOISE] what was left [inaudible]

01:03:11.010 --> 01:03:14.265
So you can think about this as really deleting from-

01:03:14.265 --> 01:03:18.240
What if I'm considering [NOISE]

01:03:18.240 --> 01:03:21.390
[inaudible] Like in the original problem you said we're transferring "s" to "t".

01:03:21.390 --> 01:03:23.460
Yeah. Yeah. Yeah. So, um, um,

01:03:23.460 --> 01:03:28.800
because of this I'm kind of trying to re-frame the [NOISE] problem a little bit. Okay,

01:03:28.800 --> 01:03:31.005
so which one should I choose? Yeah.

01:03:31.005 --> 01:03:32.880
What about the substitution the other way?

01:03:32.880 --> 01:03:38.130
Um, the substitution the other way meaning change-

01:03:38.130 --> 01:03:39.705
"s" to "t".

01:03:39.705 --> 01:03:42.540
Sorry there's too many s's and t's here which

01:03:42.540 --> 01:03:45.375
[LAUGHTER] is going to be a bit unfortunate.

01:03:45.375 --> 01:03:48.300
And then replace the last s in cats with "t".

01:03:48.300 --> 01:03:50.340
Oh, you could-

01:03:50.340 --> 01:03:53.220
How do we eliminate that [inaudible] [NOISE]

01:03:53.220 --> 01:03:56.525
Um, that's- you can think about that as kind of equivalent.

01:03:56.525 --> 01:04:00.260
So, if you identify two letters that you want to make the same,

01:04:00.260 --> 01:04:05.370
then [NOISE] you could- you can replace the one to be the other,

01:04:05.370 --> 01:04:06.675
or the other to be that.

01:04:06.675 --> 01:04:09.810
I mean if- officially we've been kind of framing it as we're

01:04:09.810 --> 01:04:13.110
only editing "s" which is the reason that it's asymmetric.

01:04:13.110 --> 01:04:18.625
[NOISE] Okay, so which one of these?

01:04:18.625 --> 01:04:23.240
Door "a" door "b" or door "c"? Yeah.

01:04:23.240 --> 01:04:25.740
Would you look [inaudible] between "s" and "t" for

01:04:25.740 --> 01:04:29.775
every step [NOISE] [inaudible] because there's "cat" in both of them?

01:04:29.775 --> 01:04:33.885
Yeah, so you could try to look inside but,

01:04:33.885 --> 01:04:36.960
um, but remember these are- might be really complicated.

01:04:36.960 --> 01:04:41.100
So you- we wanna kind of a simple mechanized procedure to tell.

01:04:41.100 --> 01:04:42.540
[NOISE] What about the next letter?

01:04:42.540 --> 01:04:44.800
The next letter.

01:04:44.810 --> 01:04:45.910
"t" [inaudible]

01:04:45.910 --> 01:04:47.745
Um, yeah let's- let's pretend these are-

01:04:47.745 --> 01:04:49.680
you- you can't see inside them. Okay. [LAUGHTER].

01:04:49.680 --> 01:04:53.640
Keep going with each of the different cases.

01:04:53.640 --> 01:04:55.320
Yeah, okay, so let's keep on going.

01:04:55.320 --> 01:04:56.640
[NOISE] So, I'm not going to draw everything,

01:04:56.640 --> 01:04:59.910
but you can also try to break this down into- maybe there's three actions here,

01:04:59.910 --> 01:05:01.740
and three actions here. All right.

01:05:01.740 --> 01:05:06.780
Um, and at the end of the day you hopefully have a problem that's simple enough,

01:05:06.780 --> 01:05:11.010
that, um, where "s" equals "t' or something then you're done.

01:05:11.010 --> 01:05:12.900
Um, but then, you know,

01:05:12.900 --> 01:05:14.610
how- how do I- how do I know?

01:05:14.610 --> 01:05:15.750
Suppose I've solved this.

01:05:15.750 --> 01:05:17.640
Suppose if someone just told you, okay,

01:05:17.640 --> 01:05:19.230
I know this cost,

01:05:19.230 --> 01:05:22.500
I know this cost, I know this cost. What- what should you do?

01:05:22.500 --> 01:05:24.030
[inaudible]

01:05:24.030 --> 01:05:25.635
Yeah, you should take the minimum, right?

01:05:25.635 --> 01:05:27.750
Like remember we want to minimize the edit distance.

01:05:27.750 --> 01:05:30.105
So, um, there's three things you can do.

01:05:30.105 --> 01:05:34.395
Each of them has some costs of doing that action which is, you know, one.

01:05:34.395 --> 01:05:36.015
Every edit is the same cost.

01:05:36.015 --> 01:05:37.530
And then there's a cost of,

01:05:37.530 --> 01:05:39.675
you know, continuing to do whatever you're doing.

01:05:39.675 --> 01:05:43.230
And so we're just gonna take the minimum over those. Yeah.

01:05:43.230 --> 01:05:47.700
[inaudible] How do we know that that's,

01:05:47.700 --> 01:05:50.625
like- that's the maximum amount of distance that we have to take?

01:05:50.625 --> 01:05:55.065
Yeah, so I was trying to argue that, um,

01:05:55.065 --> 01:05:57.045
with- if you're going to right to left,

01:05:57.045 --> 01:05:59.490
it's, uh, without loss of generality.

01:05:59.490 --> 01:06:01.080
Because if you've- went left to right,

01:06:01.080 --> 01:06:02.220
or in some other order,

01:06:02.220 --> 01:06:05.430
you can also replay the edits, um, in order.

01:06:05.430 --> 01:06:07.770
[inaudible] [NOISE] one letter

01:06:07.770 --> 01:06:10.950
that you needed one assertion like [inaudible] like upstream.

01:06:10.950 --> 01:06:19.650
But if you went from like the left it looks like as if you're [inaudible]. [NOISE]

01:06:19.650 --> 01:06:19.800
Yeah.

01:06:19.800 --> 01:06:21.135
[inaudible] Okay.

01:06:21.135 --> 01:06:22.530
Yeah. I think it works.

01:06:22.530 --> 01:06:26.445
[NOISE] Um, okay, so- so let's, um,

01:06:26.445 --> 01:06:30.870
try to code this up and see if we can make this program work.

01:06:30.870 --> 01:06:35.055
Okay, so, um, I'm gonna do editDistance.

01:06:35.055 --> 01:06:36.645
Can everyone see this?

01:06:36.645 --> 01:06:43.350
Okay, so, um, so I'm gonna define a function that takes two strings,

01:06:43.350 --> 01:06:48.060
and then I'm going to um, define a recurrence.

01:06:48.060 --> 01:06:50.145
So, recurrences are- are,

01:06:50.145 --> 01:06:51.570
I guess, one word I haven't really used,

01:06:51.570 --> 01:06:55.020
but this is really the way you should th- kind of think about, uh,

01:06:55.020 --> 01:06:59.460
dynamic programs, and this idea of taking complex problems and breaking it down.

01:06:59.460 --> 01:07:00.540
It's gonna show up, in you know,

01:07:00.540 --> 01:07:04.455
search problems, MDPs, and, you know, games.

01:07:04.455 --> 01:07:08.340
So, I guess it's something that you should really be comfortable with.

01:07:08.340 --> 01:07:15.435
So, let's um, define recurrence, uh, as follows.

01:07:15.435 --> 01:07:18.225
Um, so remember at any point in time,

01:07:18.225 --> 01:07:21.315
I have, uh, let's say a sub problem,

01:07:21.315 --> 01:07:23.040
and since I'm going right to left,

01:07:23.040 --> 01:07:25.140
I'm only considering the first,

01:07:25.140 --> 01:07:29.670
um, "m" letters of "s" and the first letter "n" letters of "t".

01:07:29.670 --> 01:07:36.870
Okay, so recurse is going to return the minimum edit distance between two things,

01:07:36.870 --> 01:07:40.155
the first "m" letters of "s",

01:07:40.155 --> 01:07:42.580
and the first "n" letters of "t".

01:07:42.580 --> 01:07:45.320
Um, I'm gonna post this online so you guys don't have to,

01:07:45.320 --> 01:07:47.495
like, copy- try to copy this.

01:07:47.495 --> 01:07:51.875
Um, okay, so, um,

01:07:51.875 --> 01:07:54.400
okay, suppose I'm gonna- I'm gonna define this function.

01:07:54.400 --> 01:07:57.730
Uh, if I have this function what should I return?

01:07:59.840 --> 01:08:01.890
Recurse of-.

01:08:01.890 --> 01:08:06.510
[inaudible]

01:08:06.510 --> 01:08:08.640
So "m" is an integer, right?

01:08:08.640 --> 01:08:11.520
So "n" is an integer,

01:08:11.520 --> 01:08:14.850
so I'm going to return the length of "m" and the length of "n".

01:08:14.850 --> 01:08:16.950
Okay, so that's kind of, uh,

01:08:16.950 --> 01:08:18.180
the initial state.

01:08:18.180 --> 01:08:20.460
[OVERLAPPING]

01:08:20.460 --> 01:08:26.760
Sorry. Yup. Okay. Um, All right.

01:08:26.760 --> 01:08:28.620
So now you need to fill out this function.

01:08:28.620 --> 01:08:31.200
Okay, so let's- let's um,

01:08:31.200 --> 01:08:33.600
consider a bunch of cases.

01:08:33.600 --> 01:08:35.775
So here's some easy cases.

01:08:35.775 --> 01:08:39.030
Suppose that, um, "m" is zero, right?

01:08:39.030 --> 01:08:43.350
So I have- comparing an empty string with something that has "n" letters.

01:08:43.350 --> 01:08:45.930
So, what should the cost of that be?

01:08:45.930 --> 01:08:51.210
[NOISE] I heard some mumbling.

01:08:51.210 --> 01:08:51.310
[OVERLAPPING].

01:08:51.310 --> 01:08:57.420
It should be "n" [NOISE] and symmetrically if "n" is 0 then result should be "m",

01:08:57.420 --> 01:09:02.100
um, and then if now we come to the kind of

01:09:02.100 --> 01:09:06.150
initial case that we consider which is the end [NOISE] match a match.

01:09:06.150 --> 01:09:09.375
So, if "s" um,

01:09:09.375 --> 01:09:11.400
the last letter of "m",

01:09:11.400 --> 01:09:14.100
you know, this is 0-based indexing.

01:09:14.100 --> 01:09:16.575
Um, so that's why there's a minus 1.

01:09:16.575 --> 01:09:17.850
So, this matches.

01:09:17.850 --> 01:09:22.530
[NOISE] Then what should I do?

01:09:22.530 --> 01:09:28.350
[NOISE] So, now we reduce this to a sub problem, right?

01:09:28.350 --> 01:09:29.100
[inaudible]

01:09:29.100 --> 01:09:32.670
So, I have "m" minus 1 and "n" minus 1.

01:09:32.670 --> 01:09:37.860
Okay. And now comes the fun case which we looked at.

01:09:37.860 --> 01:09:41.070
So there's- um, in this case the last letter doesn't match.

01:09:41.070 --> 01:09:44.955
So, I'm gonna to have to do some sort of edit, can't just let it slide. Yeah. Question.

01:09:44.955 --> 01:09:47.430
Would you- do you need a full "s" to "t" compare

01:09:47.430 --> 01:09:51.700
or "s" through "m" and then "t" through "n" to compare?

01:09:52.340 --> 01:09:56.340
Worse than doing a full s, a compare.

01:09:56.340 --> 01:10:00.945
[OVERLAPPING] rather than waiting until, um, first-

01:10:00.945 --> 01:10:01.530
Yeah.

01:10:01.530 --> 01:10:02.550
-stream at the last slide than that.

01:10:02.550 --> 01:10:05.115
There- there's probably a way you can make this more efficient.

01:10:05.115 --> 01:10:07.365
I'm just gonna try to get the basic thing in there.

01:10:07.365 --> 01:10:10.035
Okay. So substitution.

01:10:10.035 --> 01:10:11.910
Okay. So what's a cost of a substitution?

01:10:11.910 --> 01:10:13.905
I pay 1 to do the substitution,

01:10:13.905 --> 01:10:17.760
but and in- as a reward I get to, um,

01:10:17.760 --> 01:10:21.660
reduce the problem to n minus 1 and n minus 1, right?

01:10:21.660 --> 01:10:27.795
So I lop off a letter from s and I lop off a letter from t. So what else can I do?

01:10:27.795 --> 01:10:31.320
So I can, um, you know, delete.

01:10:31.320 --> 01:10:33.990
[NOISE] So that also costs 1.

01:10:33.990 --> 01:10:35.565
And when I delete,

01:10:35.565 --> 01:10:40.995
I delete from s and then n. So this remains the same.

01:10:40.995 --> 01:10:44.925
And then now you can think about the insertion,

01:10:44.925 --> 01:10:49.530
um, is n minus 1, right?

01:10:49.530 --> 01:10:52.260
Because remember insertion into s is deletion from t,

01:10:52.260 --> 01:10:54.490
that's why this is n minus 1.

01:10:54.530 --> 01:10:59.910
Okay. And then the result is just gonna be a minimum of,

01:10:59.910 --> 01:11:05.320
uh, all these things. Okay. Return result.

01:11:07.460 --> 01:11:10.110
Okay. So just, uh,

01:11:10.110 --> 01:11:12.450
and then, how do I call this function?

01:11:12.450 --> 01:11:16.260
Um, a cat, the cats.

01:11:16.260 --> 01:11:21.000
[NOISE] So let me print out the answer.

01:11:21.000 --> 01:11:27.790
Um, let's see if it works.

01:11:28.070 --> 01:11:30.795
Okay. Print out 4.

01:11:30.795 --> 01:11:32.700
Therefore, I conclude it works now.

01:11:32.700 --> 01:11:35.940
[LAUGHTER] I mean if you were doing this, uh,

01:11:35.940 --> 01:11:37.230
you would probably want to test it some more,

01:11:37.230 --> 01:11:38.445
but in the interest of the time,

01:11:38.445 --> 01:11:39.480
I'll kind of move on.

01:11:39.480 --> 01:11:41.340
So let me just kinda refresh.

01:11:41.340 --> 01:11:44.250
Okay. So I'm computing this at a distance between

01:11:44.250 --> 01:11:48.345
two strings and we're gonna define a recurrence that works on sub problems,

01:11:48.345 --> 01:11:52.380
where the sub problem is the first m letters of s and the first n letters of

01:11:52.380 --> 01:11:56.565
t. And the reason I'm using integers instead of,

01:11:56.565 --> 01:11:59.325
um, strings is to avoid like string copying,

01:11:59.325 --> 01:12:02.100
um, implementation detail, but it doesn't really matter.

01:12:02.100 --> 01:12:05.080
Um, so base cases.

01:12:05.300 --> 01:12:10.110
So you wanna reduce your problem to a case where it's- it's trivial to solve.

01:12:10.110 --> 01:12:13.630
Um, and then we have the last letter matches.

01:12:13.630 --> 01:12:16.985
And then we have a letter doesn't match and you have to pay some sort of cost.

01:12:16.985 --> 01:12:18.410
I don't know which action to take.

01:12:18.410 --> 01:12:20.960
So I'm gonna take them, you know, minimum of all of them.

01:12:20.960 --> 01:12:24.515
And then I call it by just calling, you know, recurse.

01:12:24.515 --> 01:12:26.960
Okay. So this is great, right?

01:12:26.960 --> 01:12:28.740
So now I have a working thing.

01:12:28.740 --> 01:12:31.425
[NOISE] Um, let's try another test case.

01:12:31.425 --> 01:12:33.150
So I'm gonna make this.

01:12:33.150 --> 01:12:36.525
Um, so if I do times 10,

01:12:36.525 --> 01:12:38.370
this, uh, basically, uh,

01:12:38.370 --> 01:12:40.665
replicates this string 10 times.

01:12:40.665 --> 01:12:43.410
So it's a- it's a long string-longer string.

01:12:43.410 --> 01:12:45.420
[NOISE] Okay.

01:12:45.420 --> 01:12:46.860
So now I'm gonna run it.

01:12:46.860 --> 01:12:54.330
[OVERLAPPING] Maybe I shouldn't wait for this.

01:12:54.330 --> 01:12:55.410
Is there a base case?

01:12:55.410 --> 01:12:57.885
Um, there is a base case, I- I think that it expanded-

01:12:57.885 --> 01:13:00.615
it's- what- what's wrong with this code?

01:13:00.615 --> 01:13:01.395
Very slow.

01:13:01.395 --> 01:13:04.500
Um, yes, it's very slow. Why is it slow?

01:13:04.500 --> 01:13:08.160
[BACKGROUND] Yeah, right?

01:13:08.160 --> 01:13:10.170
So- so I'm recursing.

01:13:10.170 --> 01:13:12.690
[NOISE] Every point recurses three times.

01:13:12.690 --> 01:13:15.510
So you kind of get this exponential, you know, blob.

01:13:15.510 --> 01:13:19.200
Um, so there's kind of a- how do you solve this problem?

01:13:19.200 --> 01:13:24.120
[BACKGROUND] Yeah.

01:13:24.120 --> 01:13:26.370
You can memo I think I heard the word memoize,

01:13:26.370 --> 01:13:28.365
which is another way to kind of think about.

01:13:28.365 --> 01:13:30.900
Memorize plus, um, I guess,

01:13:30.900 --> 01:13:34.425
recurrences is dynamic programming, I guess.

01:13:34.425 --> 01:13:38.055
Um, so I'm gonna show you kind of this,

01:13:38.055 --> 01:13:42.120
um, way to do it which is pretty, uh, uninvasive.

01:13:42.120 --> 01:13:44.580
Um, and generally I recommend people.

01:13:44.580 --> 01:13:49.290
Well, get the slow version working [NOISE] and then try to make it faster.

01:13:49.290 --> 01:13:50.370
Don't try to be, you know,

01:13:50.370 --> 01:13:52.530
too slick at once.

01:13:52.530 --> 01:13:55.575
Okay. So I'm gonna make this cache, right?

01:13:55.575 --> 01:13:57.300
And I'm gonna say if m,

01:13:57.300 --> 01:13:58.935
n is in the cache,

01:13:58.935 --> 01:14:02.130
then I'm gonna return whatever's in the cache.

01:14:02.130 --> 01:14:05.280
So cache is just a dictionary mapping.

01:14:05.280 --> 01:14:07.335
Um, the key which is, um,

01:14:07.335 --> 01:14:09.840
identification of the problem I'm interested in solving,

01:14:09.840 --> 01:14:12.570
and the result which is the answer that I computed.

01:14:12.570 --> 01:14:16.020
So if I already computed it, I don't need a computer again, just return it.

01:14:16.020 --> 01:14:19.620
And then at the end, if I have to compute it,

01:14:19.620 --> 01:14:23.700
then, um, I have to put this in the cache.

01:14:23.700 --> 01:14:29.145
[NOISE] Okay?

01:14:29.145 --> 01:14:32.595
So three lines or four lines, I guess.

01:14:32.595 --> 01:14:36.420
Yeah. [BACKGROUND] [NOISE] Yeah.

01:14:36.420 --> 01:14:37.710
That's a great point.

01:14:37.710 --> 01:14:40.260
Uh, this should be outside of the recurse object.

01:14:40.260 --> 01:14:43.680
Yeah. Glad you guys are paying attention.

01:14:43.680 --> 01:14:47.220
Um, otherwise, yeah, it would do basically nothing.

01:14:47.220 --> 01:14:50.025
Any other mistakes? [LAUGHTER] Yeah.

01:14:50.025 --> 01:14:53.735
Um, there is also function decorators that like implement memoizing for you.

01:14:53.735 --> 01:14:56.120
In this class, are you okay if we use that or would you

01:14:56.120 --> 01:14:58.370
rather us like make our own in this case?

01:14:58.370 --> 01:15:02.375
Um, you can use the deco- you can be fancy if you want.

01:15:02.375 --> 01:15:02.690
Okay.

01:15:02.690 --> 01:15:04.915
Um, yeah. But- but I think this is,

01:15:04.915 --> 01:15:06.060
you know, pretty transparent.

01:15:06.060 --> 01:15:08.370
Easy for learning purposes.

01:15:08.370 --> 01:15:10.965
Okay. So let's run this.

01:15:10.965 --> 01:15:14.490
So now it runs instantaneously as opposed

01:15:14.490 --> 01:15:18.225
to- I actually don't know how long it would have taken otherwise.

01:15:18.225 --> 01:15:22.680
Okay. And sanity check for t is

01:15:22.680 --> 01:15:24.480
probably the right answer because there's

01:15:24.480 --> 01:15:27.285
four was the original answer and multiply by 10.

01:15:27.285 --> 01:15:30.120
Okay. any other questions about this?

01:15:30.120 --> 01:15:33.195
[NOISE] So this is an example of,

01:15:33.195 --> 01:15:34.890
you know, kind of basic, uh,

01:15:34.890 --> 01:15:37.335
dynamic programming which are, uh,

01:15:37.335 --> 01:15:40.500
you'd solve a problem trying to formulate it as

01:15:40.500 --> 01:15:44.490
a recurrence of a complicated problem in terms of smaller problems.

01:15:44.490 --> 01:15:48.150
Um, and like I said before this is gonna kind of show up,

01:15:48.150 --> 01:15:52.150
um, um, over and over again in this class.

01:15:52.760 --> 01:16:00.150
Yeah. [BACKGROUND] Yeah.

01:16:00.150 --> 01:16:02.910
So the question is why does this reduce, uh, redundancy.

01:16:02.910 --> 01:16:04.710
[NOISE] Is that right?

01:16:04.710 --> 01:16:07.800
Um, so maybe I can do it kinda pictorially.

01:16:07.800 --> 01:16:10.470
Um, if you think about, let's say, you have a,

01:16:10.470 --> 01:16:13.200
um, a problem here, right?

01:16:13.200 --> 01:16:15.000
And this gets, um,

01:16:15.000 --> 01:16:17.070
you know, reduced to,

01:16:17.070 --> 01:16:23.670
um, um, I'm just making kind of a arbitrary, um, diagram here.

01:16:23.670 --> 01:16:25.725
So this problem gets reduced to these two.

01:16:25.725 --> 01:16:28.650
And this problem gets reduced to these two, um,

01:16:28.650 --> 01:16:32.730
and- and so on, um, right?

01:16:32.730 --> 01:16:37.695
So if you think about- if you didn't have memoization,

01:16:37.695 --> 01:16:40.905
you will just be paying for the number of paths.

01:16:40.905 --> 01:16:43.830
Every path is a kind of you have to compute from scratch.

01:16:43.830 --> 01:16:46.500
Whereas, if you do memoization,

01:16:46.500 --> 01:16:48.660
you pay the number of nodes here,

01:16:48.660 --> 01:16:51.675
which a lot of this has shared like here.

01:16:51.675 --> 01:16:53.745
Um, you know, once you compute this,

01:16:53.745 --> 01:16:55.560
no matter if you're coming from here or here,

01:16:55.560 --> 01:16:57.940
you're kind of using the same value.

01:16:58.220 --> 01:17:01.590
Okay. So let's- let's move on.

01:17:01.590 --> 01:17:04.320
So the second problem, um,

01:17:04.320 --> 01:17:07.560
we're gonna talk about is,

01:17:07.560 --> 01:17:09.780
uh, has to do with continuous optimization.

01:17:09.780 --> 01:17:14.805
[NOISE] And the motivating question here is how do you do, um, regression?

01:17:14.805 --> 01:17:16.620
Which is a kind of a bread and butter of,

01:17:16.620 --> 01:17:18.210
um, you know, machine learning here.

01:17:18.210 --> 01:17:21.360
[NOISE]

01:17:21.360 --> 01:17:28.810
So here we go.

01:17:28.910 --> 01:17:36.495
Regression. Okay. So imagine you get some points.

01:17:36.495 --> 01:17:43.150
Okay, so I give you a point which is 2, 4.

01:17:43.220 --> 01:17:45.645
Then I give you another point,

01:17:45.645 --> 01:17:49.210
let's say 4, 2.

01:17:50.090 --> 01:17:53.130
And so these are data points, you want to, let's say,

01:17:53.130 --> 01:17:56.940
predict housing price from,

01:17:56.940 --> 01:17:58.920
you know, square footage or something like that.

01:17:58.920 --> 01:18:01.600
You want to predict health score from,

01:18:01.600 --> 01:18:03.950
um, your blood pressure and some other things.

01:18:03.950 --> 01:18:06.155
So this is pretty common in machine learning.

01:18:06.155 --> 01:18:10.535
And the question is how do you fit a line?

01:18:10.535 --> 01:18:13.180
I'm going to consider the case where

01:18:13.180 --> 01:18:16.530
your line has to go through the origin, just for simplicity.

01:18:16.530 --> 01:18:20.310
Um, so you might want to like find, you know, a fit.

01:18:20.310 --> 01:18:23.250
Two points is maybe kind of a little bit degenerate,

01:18:23.250 --> 01:18:26.310
but that's the simple example we are going to work with.

01:18:26.310 --> 01:18:30.315
In general you have lots of points and you want this to fit the line that best kind of,

01:18:30.315 --> 01:18:32.490
uh, is close to the points.

01:18:32.490 --> 01:18:36.735
Okay, so how do you do this?

01:18:36.735 --> 01:18:43.045
So there's a principle called least squares, which says, well,

01:18:43.045 --> 01:18:49.355
if you give me a line which is given in this case by a slope w,

01:18:49.355 --> 01:18:53.015
I'm going to tell you how bad this is.

01:18:53.015 --> 01:18:57.580
And badness is measured by looking at all the training points,

01:18:57.580 --> 01:19:00.180
and looking at these distances.

01:19:00.180 --> 01:19:04.560
Right. So here I have, you know,

01:19:04.560 --> 01:19:07.695
this particular, uh, a particular,

01:19:07.695 --> 01:19:09.600
let's say point x_i.

01:19:09.600 --> 01:19:11.850
If I hit it with a w,

01:19:11.850 --> 01:19:13.680
then I get, basically the,

01:19:13.680 --> 01:19:17.880
uh, you know, the y-intercept here,

01:19:17.880 --> 01:19:20.145
not the y-intercept but the- like the y value here.

01:19:20.145 --> 01:19:24.270
That's my prediction. The real value was y_i,

01:19:24.270 --> 01:19:26.445
which is, you know, up here.

01:19:26.445 --> 01:19:28.290
And so if I look at the difference,

01:19:28.290 --> 01:19:30.120
I want that difference to be zero.

01:19:30.120 --> 01:19:33.270
Right. So in, in least squares, I square this,

01:19:33.270 --> 01:19:37.680
and I say, I want this to be as small as possible, right.

01:19:37.680 --> 01:19:39.570
Now, this is only for one point.

01:19:39.570 --> 01:19:42.660
So I'm going to look at all the points.

01:19:42.660 --> 01:19:44.700
Let's suppose I have n points,

01:19:44.700 --> 01:19:50.325
and that's a function that I'm going to call f of w,

01:19:50.325 --> 01:19:55.320
which basically says, for a given weight vector,

01:19:55.320 --> 01:20:00.840
which is a slope, give me a number that characterizes how bad of a fit, um, this is.

01:20:00.840 --> 01:20:03.495
Where 0 means that I fit everything perfectly,

01:20:03.495 --> 01:20:06.930
and large numbers mean that I fit poorly.

01:20:06.930 --> 01:20:10.470
Okay? All right.

01:20:10.470 --> 01:20:12.915
So, so that's your regression.

01:20:12.915 --> 01:20:16.485
So how do I solve a regression problem?

01:20:16.485 --> 01:20:19.230
So how do I optimize this?

01:20:19.230 --> 01:20:22.485
Can you do this in your head?

01:20:22.485 --> 01:20:25.600
So if I actually had these two points, what should w be?

01:20:32.330 --> 01:20:36.255
Okay, it doesn't matter. We'll, we'll compute it.

01:20:36.255 --> 01:20:40.630
So how do we go about doing this?

01:20:44.630 --> 01:20:49.545
So one principle, which is maybe another general takeaway is,

01:20:49.545 --> 01:20:52.900
abstract away the details.

01:20:53.090 --> 01:20:58.830
Right. Um, this is also true with the dynamic programming, but sometimes, you know,

01:20:58.830 --> 01:21:01.020
you get- if you're too close to the board, and you're looking at,

01:21:01.020 --> 01:21:03.960
oh man, these, these points are here and I need to fit this line.

01:21:03.960 --> 01:21:09.510
How do I do that? You kind of get kind of a little bit stuck.

01:21:09.510 --> 01:21:11.670
Why don't we think about this f,

01:21:11.670 --> 01:21:13.440
as say some function?

01:21:13.440 --> 01:21:15.495
I don't, I don't really care what it is.

01:21:15.495 --> 01:21:17.400
And let's plot this function.

01:21:17.400 --> 01:21:19.980
Okay. So now this is a different plot.

01:21:19.980 --> 01:21:22.080
Now, this is, ah, the weight,

01:21:22.080 --> 01:21:27.675
and this is f of w. [NOISE] Always label your axes.

01:21:27.675 --> 01:21:31.155
And let's say this function looks like this.

01:21:31.155 --> 01:21:35.250
Okay. So which means that for this slope,

01:21:35.250 --> 01:21:36.990
I pay this, you know, amount,

01:21:36.990 --> 01:21:40.275
for this slope, I pay this amount and, and so on.

01:21:40.275 --> 01:21:44.325
And what I want to do, I want to minimize f of w,

01:21:44.325 --> 01:21:46.499
which means, I want to find,

01:21:46.499 --> 01:21:49.065
um, the w which,

01:21:49.065 --> 01:21:53.805
um, has the least value of f of w, right?

01:21:53.805 --> 01:21:59.670
Question? Okay. So you take the derivative.

01:21:59.670 --> 01:22:02.410
So what is the derivative giving you?

01:22:02.810 --> 01:22:05.910
It tells you where to move, right?

01:22:05.910 --> 01:22:07.485
So if you look over here,

01:22:07.485 --> 01:22:09.420
so you can- in general,

01:22:09.420 --> 01:22:11.640
you might not be able to get there directly,

01:22:11.640 --> 01:22:14.880
in this actually particular case you can because you can solve it in closed form,

01:22:14.880 --> 01:22:17.805
but I'm going to try to be more general.

01:22:17.805 --> 01:22:20.235
Um, so you start here.

01:22:20.235 --> 01:22:22.485
This, this derivative tells you,

01:22:22.485 --> 01:22:25.110
well, the function is decreasing if you move to the right.

01:22:25.110 --> 01:22:26.775
So then you should move to the right.

01:22:26.775 --> 01:22:28.410
Whereas over here, if you end up over here,

01:22:28.410 --> 01:22:31.965
the derivative says, the function is decreasing as we move to the left.

01:22:31.965 --> 01:22:34.230
So you should move to the left, right?

01:22:34.230 --> 01:22:39.045
So what I'm going to introduce is this,

01:22:39.045 --> 01:22:41.100
uh, algorithm called gradient descent.

01:22:41.100 --> 01:22:43.605
It's a very simple algorithm.

01:22:43.605 --> 01:22:48.405
It basically says, start with some place,

01:22:48.405 --> 01:22:50.625
and then compute the derivative,

01:22:50.625 --> 01:22:52.050
and just follow your nose.

01:22:52.050 --> 01:22:54.240
Right? If the derivative says it's negative,

01:22:54.240 --> 01:22:55.425
then just go this way.

01:22:55.425 --> 01:22:56.865
And now you're on a new point,

01:22:56.865 --> 01:22:58.575
you compute the derivative again,

01:22:58.575 --> 01:23:01.380
you descend, and now you compute it again.

01:23:01.380 --> 01:23:04.110
And then maybe you compute the derivative and it

01:23:04.110 --> 01:23:07.095
says keep on going this way and maybe you overshoot, and then you come back.

01:23:07.095 --> 01:23:11.280
And then, you know, hopefully you'll end up at the minimum.

01:23:11.280 --> 01:23:18.250
Okay. So let's try to see what this looks like in code.

01:23:22.550 --> 01:23:26.970
So gradient descent is one of the simplest algorithms,

01:23:26.970 --> 01:23:29.835
but it really underlies

01:23:29.835 --> 01:23:33.645
essentially all the algorithms that you people use in machine learning.

01:23:33.645 --> 01:23:35.940
So let's do points.

01:23:35.940 --> 01:23:37.785
We have two points here.

01:23:37.785 --> 01:23:42.540
Um, and I'm going to define, um, some functions.

01:23:42.540 --> 01:23:47.235
Okay, so f of w, so what is this function?

01:23:47.235 --> 01:23:50.820
So I'm going to sum over all the different,

01:23:50.820 --> 01:23:54.765
um, you know, and basically at this point it's converting math into Python.

01:23:54.765 --> 01:23:59.595
So I'm going to look at all the points.

01:23:59.595 --> 01:24:01.905
So for every x, y,

01:24:01.905 --> 01:24:06.060
what the model predicts is w times x minus y.

01:24:06.060 --> 01:24:07.875
And if I square that,

01:24:07.875 --> 01:24:13.575
that's going to be the error that I get on that point.

01:24:13.575 --> 01:24:18.840
Then, if I sum over all these errors then I get my objective function.

01:24:18.840 --> 01:24:27.990
Okay. Array of- so yeah.

01:24:27.990 --> 01:24:30.030
So you can put array here if you want,

01:24:30.030 --> 01:24:31.275
but it doesn't matter.

01:24:31.275 --> 01:24:33.310
It's, it's actually fine.

01:24:33.770 --> 01:24:36.885
Okay. So now I need to compute the derivative.

01:24:36.885 --> 01:24:39.030
So how do you compute the derivative?

01:24:39.030 --> 01:24:40.980
So if your calculus is a little bit rusty,

01:24:40.980 --> 01:24:44.280
you might want to brush up on it. So what's the derivative?

01:24:44.280 --> 01:24:47.910
Re- remember we're taking the derivative with respect to w, right?

01:24:47.910 --> 01:24:48.960
There's a lot of symbols here.

01:24:48.960 --> 01:24:51.645
Always remember what you're taking derivative with respect to.

01:24:51.645 --> 01:24:55.605
Okay. The derivative of the sum is the sum of the derivative.

01:24:55.605 --> 01:24:58.440
So now I need to take the derivative of this.

01:24:58.440 --> 01:25:01.215
Right. And what's the derivative of this?

01:25:01.215 --> 01:25:05.175
Something squared, um, you bring the two down here,

01:25:05.175 --> 01:25:08.010
and now you multiply by the derivative of this.

01:25:08.010 --> 01:25:10.470
And what's the derivative of this?

01:25:10.470 --> 01:25:15.870
Should be x. Right? Because this is a- y, this is a constant,

01:25:15.870 --> 01:25:21.915
and w derivative- w times x with respect to w is x. Okay. So that's it.

01:25:21.915 --> 01:25:26.040
Okay, so now let's do gradient descent.

01:25:26.040 --> 01:25:28.920
Let's initialize with w equal 0.

01:25:28.920 --> 01:25:31.095
Then I'm going to just, um,

01:25:31.095 --> 01:25:33.705
you know, iterate a hundred times.

01:25:33.705 --> 01:25:35.820
Normally, you would set some sort of stopping condition,

01:25:35.820 --> 01:25:39.165
but let's just keep it simple for now.

01:25:39.165 --> 01:25:42.855
Okay, so for every moment, I'm going to- I have a w,

01:25:42.855 --> 01:25:45.540
I can compute the value of the function,

01:25:45.540 --> 01:25:48.210
and also take the gradient of the derivative.

01:25:48.210 --> 01:25:51.360
Gradient just means derivative in higher di- dimensions,

01:25:51.360 --> 01:25:53.430
which we'll want later.

01:25:53.430 --> 01:25:57.765
Um, okay. And then, what do I do?

01:25:57.765 --> 01:26:00.600
I take, uh, w,

01:26:00.600 --> 01:26:04.455
and I subtract the, the gradient.

01:26:04.455 --> 01:26:10.725
Okay. So remember- okay, I'll be out of here.

01:26:10.725 --> 01:26:15.000
Okay. So, uh, I take the gradient.

01:26:15.000 --> 01:26:17.985
Remember I want to have the gradient.

01:26:17.985 --> 01:26:20.160
Uh, gradient tells me where the function is increasing,

01:26:20.160 --> 01:26:22.110
so I want to move in the opposite direction.

01:26:22.110 --> 01:26:24.270
And eta is just going to be this, uh,

01:26:24.270 --> 01:26:26.115
step size to, um,

01:26:26.115 --> 01:26:27.330
keeping things under control.

01:26:27.330 --> 01:26:29.175
We'll talk more about that next time.

01:26:29.175 --> 01:26:33.300
Okay, so now, I want to do, print out what's going on here.

01:26:33.300 --> 01:26:42.975
So iteration, print out the function, and t value.

01:26:42.975 --> 01:26:50.040
Okay. All right, so let's compute the gradient.

01:26:50.040 --> 01:26:55.350
And, um, so you can see that the iteration, we first start out with w equal 0.

01:26:55.350 --> 01:26:58.670
Then it moves to 0.3, then it moves to

01:26:58.670 --> 01:27:03.525
0.79999999 and then it looks like it's converging into 0.8.

01:27:03.525 --> 01:27:06.270
And meanwhile, the function value is going down from 20

01:27:06.270 --> 01:27:09.315
to 7.2 which happens to be the optimal answer.

01:27:09.315 --> 01:27:11.895
So the correct answer here is 0.8.

01:27:11.895 --> 01:27:13.875
Okay, so that's it.

01:27:13.875 --> 01:27:15.105
Next time we're going to keep,

01:27:15.105 --> 01:27:19.150
uh, we're going to start on the machine learning lecture.

